{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flowershd5words', 'flowershd5dataset']\n",
      "['flowers.hdf5']\n",
      "['flowers.hdf5.words']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "print(os.listdir(\"../input/flowershd5dataset/flowers-hd5/data/flowers/\"))\n",
    "print(os.listdir(\"../input/flowershd5words/\"))\n",
    "hdf5_fpath = \"../input/flowershd5dataset/flowers-hd5/data/flowers/flowers.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported!\n"
     ]
    }
   ],
   "source": [
    "#All imports are here\n",
    "\n",
    "import io\n",
    "import h5py\n",
    "import argparse\n",
    "import torch\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from datetime import timedelta\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "print(\"All libraries imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train', 'valid']\n",
      "\n",
      "No. of items in test =  5775\n",
      "\n",
      "No. of items in train =  29390\n",
      "\n",
      "No. of items in valid =  5780\n"
     ]
    }
   ],
   "source": [
    "#view contents in HDF5 files\n",
    "f = h5py.File(hdf5_fpath)\n",
    "\n",
    "#1. to know the categories in hdf5 file\n",
    "print(list(f))\n",
    "print(\"\\nNo. of items in test = \",len(list(f['test'])))\n",
    "print(\"\\nNo. of items in train = \",len(list(f['train'])))\n",
    "print(\"\\nNo. of items in valid = \",len(list(f['valid'])))\n",
    "\n",
    "#2. see what data is stored in each category\n",
    "#print(\"\\n\\ntest = \\n\",list(f['test']))\n",
    "\n",
    "#print(\"\\n\\ntrain = \\n\",list(f['train']))\n",
    "\n",
    "#print(\"\\n\\nvalid = \\n\",list(f['valid']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BOTTOM-UP approach ahead!!!**\n",
    "\n",
    "The code in the next cell follows bottom up execution flow, to understand which method is getting called when start from the last part i.e., **runtime.py** code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating fresh params for discriminator\n",
      "creating fresh params for generator\n",
      "***Calling Nearest Neighbour***\n",
      "start creating data for NN test source_flowers_only_nn_data.pl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading data for NN test\n",
      "*** Inside train() func ***\n",
      "*** Inside _train_gan() func ***\n",
      "Epoch: 0, d_loss= 1.716500, g_loss= 36.781662, ccaD(X)= 0.528411, D(G(X))= 0.373504\n",
      "Epoch: 0, d_loss= 1.741338, g_loss= 32.317123, ccaD(X)= 0.294245, D(G(X))= 0.044435\n",
      "Epoch: 0, d_loss= 1.424124, g_loss= 35.969864, ccaD(X)= 0.820278, D(G(X))= 0.545521\n",
      "Epoch: 0, d_loss= 1.150275, g_loss= 33.303993, ccaD(X)= 0.688869, D(G(X))= 0.351557\n",
      "Epoch: 0, d_loss= 1.245203, g_loss= 28.948345, ccaD(X)= 0.750029, D(G(X))= 0.493707\n",
      "Epoch: 0, d_loss= 1.198889, g_loss= 28.865797, ccaD(X)= 0.777470, D(G(X))= 0.500923\n",
      "Epoch: 0, d_loss= 0.928548, g_loss= 26.924484, ccaD(X)= 0.730334, D(G(X))= 0.292914\n",
      "Epoch: 0, d_loss= 1.041497, g_loss= 26.134651, ccaD(X)= 0.469916, D(G(X))= 0.125429\n",
      "Epoch: 0, d_loss= 1.057591, g_loss= 27.319424, ccaD(X)= 0.636918, D(G(X))= 0.323328\n",
      "Epoch: 0, d_loss= 1.452828, g_loss= 26.760561, ccaD(X)= 0.820168, D(G(X))= 0.564743\n",
      "Epoch: 0, d_loss= 0.935445, g_loss= 24.869736, ccaD(X)= 0.522622, D(G(X))= 0.152515\n",
      "Epoch: 0, d_loss= 1.001384, g_loss= 24.608038, ccaD(X)= 0.497580, D(G(X))= 0.167959\n",
      "Epoch: 0, d_loss= 1.199445, g_loss= 25.474504, ccaD(X)= 0.760325, D(G(X))= 0.469135\n",
      "Epoch: 0, d_loss= 1.089148, g_loss= 25.507286, ccaD(X)= 0.607507, D(G(X))= 0.362356\n",
      "Epoch: 0, d_loss= 1.184351, g_loss= 24.465923, ccaD(X)= 0.444297, D(G(X))= 0.167593\n",
      "Epoch: 0, d_loss= 0.948594, g_loss= 24.513805, ccaD(X)= 0.518322, D(G(X))= 0.151200\n",
      "Epoch: 0, d_loss= 1.087856, g_loss= 26.100035, ccaD(X)= 0.727143, D(G(X))= 0.428002\n",
      "Epoch: 0, d_loss= 1.942133, g_loss= 24.695057, ccaD(X)= 0.210115, D(G(X))= 0.107592\n",
      "Epoch: 0, d_loss= 1.254090, g_loss= 26.005112, ccaD(X)= 0.798769, D(G(X))= 0.539950\n",
      "Epoch: 0, d_loss= 0.930410, g_loss= 26.210144, ccaD(X)= 0.665756, D(G(X))= 0.300016\n",
      "Epoch: 0, d_loss= 0.836020, g_loss= 26.354172, ccaD(X)= 0.756456, D(G(X))= 0.308392\n",
      "Epoch: 0, d_loss= 0.913079, g_loss= 25.555290, ccaD(X)= 0.660381, D(G(X))= 0.278315\n",
      "Epoch: 0, d_loss= 1.098739, g_loss= 28.209930, ccaD(X)= 0.757557, D(G(X))= 0.458488\n",
      "*** Calling test() ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:672: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:673: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:677: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake_source shape:  torch.Size([128, 3, 64, 64])\n",
      "text description:  this yellow and red flower has many densely layered rounded petals.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:672: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:673: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:677: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake_source shape:  torch.Size([128, 3, 64, 64])\n",
      "text description:  this yellow and red flower has many densely layered rounded petals.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnXuw1dWV579LlIeA8kYEwkNeggoKIkhiI7Y2sRPtmu5k8tTqspvMTKYmTvdURqerprqnpqtNT9UkM9XTSTOdTOxU2leMQuz4oFGMxKhcVAQUwkNezeUiVy4gAnphzR/n3Py+e3HuvedezuNeft9P1a27fmfv8/vt89jnt9Zea69l7g4hRL64oN4DEELUHk18IXKIJr4QOUQTX4gcookvRA7RxBcih2jiC5FDzmnim9lSM9tqZtvN7L5KDUoIUV2suwE8ZtYHwK8B3ApgH4B1AL7o7m9XbnhCiGpw4Tk8dz6A7e6+EwDM7GEAdwJod+KbmcIEhagy7m6d9TkXVX8sgL10vK/4mBCih3Mud/xSvypn3dHNbBmAZedwHSFEhTmXib8PwHg6Hgdgf+zk7ssBLAek6gvRUzgXVX8dgKlmNsnM+gL4AoCVlRmWEKKadPuO7+6tZvbvATwLoA+AH7j75oqNTAhRNbrtzuvWxaTqC1F1qr2qL4TopWjiC5FDNPGFyCGa+ELkEE18IXKIJr4QOUQTX4gcci4huyJvDAjHJ+oyClEBdMcXIodo4guRQ6Tqiw4ZTnJzF1T7QSR/UKnBiIqhO74QOUQTX4gcIlVfnMUVfEDfkObWtN+MSzO5aWjadnhXhQclKoru+ELkEE18IXKIJr4QOUQZeKrBTSS/FtpOVvfSI0n+BMnrQ79hJC8KbadJnjo7kzd8Pu13dO1tv5Fvevq5pK3p6izM76GNvSDEbxLJ79ZtFBVBGXiEECXRxBcih8idVw3Y7RWUrgH0U3viTAWuNTI99PcymdX7yeFpC8gV9274FkwdlclnPsrkMQfTfmMHbviNfOK6dAfPluGk3m9Ez6eXq/ddRXd8IXKIJr4QOUQTX4gcIndeNaCtaVeHMNeNF9PBxWkb9pFMJnPf4A1rvSyTB09J2+5am8m/osf/aFTa7yGy12OJ4xkk7xmRyU/2T/st3JctYPzshvDRvorSjA7HTe30E92mIu48M/uBmR00s0302DAzW2Vm24r/h3Z0DiFEz6IcVf+HAJaGx+4DsNrdpwJYXTwWQvQSylL1zWwigKfc/ari8VYAi9290czGAFjj7tPLOM95o+pzoolLQ9sskn8Z2jhKbuIVaduKo3RAbrn+QZ+6gVx4g4Ib6uaZmdySedvQGMbxFJkZIz9M29gxN41MiQu2p/0uptvGK8E1+cu5mXw8hg2KqlLNyL3R7t5YvEgjgFGd9BdC9CCqHsBjZssALKv2dYQQ5dPdid9kZmNI1T/YXkd3Xw5gOXB+qfoXkRxzyjWTCv+F0HZgRya/Hd6NM6Tef40ef++S0I9W1+fPSdtO3kIHb2fix/PTfjeSDXJRn7SthfS3BlLv54d+v7wzk5ueTtvaU++vDMfvlO52NuxRqPJGpzzQXVV/JYC7i/LdAFZUZjhCiFpQjjvvIRRcwtPNbJ+Z3QPgAQC3mtk2ALcWj4UQvYROVX13/2I7Tbe087gQooej3XndJAnAuyhtu5yM/j7BVXbR4kz+t2vSto3jM/n4uEyeFj6lcTdk8oYtadtVr2TyhfS8AcGf10zypafTtpep70La1vf6zrTfjOczeX2ILvwq6ZI/IldfhzZ9RyW6ZNdXFMXqC5FDNPGFyCFS9bvJtSQf/jhtG/XVTJ7yeGjbm8m7xqVtQ6/J5PGUq++CmWm/4ccyeWbY6DNtSSb/iFTnOwen/d4gtX1d+BZMoo1FR47QmGan/QZRZGDce7O2G0lGhgRzoYXizy65OpOPvtX1c4sU3fGFyCGa+ELkEE18IXKIbPwuwHYsec3wb0K//dsyedSBtG0s2bFbr0rbBgzJ5GNkk8/dmvY7Sfbz4CFp21EK+11A4xgwPu13in7yp4VkIWtIvpP8fr9oTvvxsMakTXiJZM7hHz12lMsTHtyiXMTvNNv18Vsbxi86R3d8IXKIJr4QOSQ/qv5Ekg+TfATt8slwPKRvJs8jHXXjjLTfH1O+uZbfStvGPkPDCDnsriTX30Daddf/M2m/4TSO0bvTtpGUFeQEud/eOpX2G0DmwpTgi1twPJP3U8D2vJ+k/Rpoq13fl9M2DgZ8n+SYZvBDTvgfXss0MncayU3Z7/m0X3hpPZ9oF/Gb1e4+18qiO74QOUQTX4gcks/02pQUb2RQuwbQLpJPhoRiIyixxTukRn+tJe13iPJV3xh+WpvIzBgVNp40k2p7OSW9WDcr7cd5+5oXpm2HKdHHBTz+H6f9dpKRdzqo6Ucoe+IASq/9XNikcwe97p+FqDteoOeCwSGnSOIZOCvY73cy8cJfZ3JrzCgXxtXr4O9IBcqqqVquEKIkmvhC5BBNfCFySC5tfPYg7bw+tJE7pc/RtG0cJaxc8mwmDwo5hEeQPX0mnP/Ymky+7F+nbWceyeQB92byJWGH3/Hfz+T+z6Zto34vk3f/FT3njrTfthcz+UgY45l/zuT5t2Xy/n9J+z0xLZNffCJto6cl7rYXJ6b9sAvtUmHTt+cQb7cVfnGy8YUQJdHEFyKH5FLV55pXE0Lk3igKLev71bTtJKnccw5l8qypab8mSkN6Y1DFz5CrbN8zaVu/mzN5KrmoTofNPINX0fnmpW3992TyUbrWS6vTfh9+OpNHxZz4JB8h86YlhMhdRbn5mvqmbX9JlX+5xNjItBtCVa4EDijkorqXhX5hH1TukaovhCiJJr4QOUQTX4gckp/deQzZ9ftC0wVkQA7/u7TttoGZzC7B1pvCOb6XyTHxxOtU1vrE2LRt46ZMPkShvQtD3vsnJ2bynaFGnZPtfoh2u70eEnHcQHb9idvTtgl0zjMTMvn/hprfcymcd82utA207nGEEoJ8FLpxCG/wnmIQhS0fovcg1ioUXaecElrjzewFM3vHzDab2TeKjw8zs1Vmtq34f2hn5xJC9AzKUfVbAfypu18JYAGAr5vZTAD3AVjt7lMBrC4eCyF6AV1255nZCgB/U/xbTKWy17j79E6e2zPceUS/cMwv4PLQxho9pcfHXeEka+l4/OS07YU3M3nYhLRtLP0M76ULeEj0cdeuTP6r42nbl6/L5CcpT920kPv/Mjrn/lCGazv532aTbv5oqKI447FMPnYsbWsgI/JjOt+7IW+fqDwVd+eZ2UQUakm8CmC0uzcWL9QIYFT7zxRC9CTKXtwzs0EAHgdwr7sfNev0R6XtecsALOu0oxCiZpR1xzezi1CY9D92958WH24qqvgo/i+ZLczdl7v7PHefV6pdCFF7OrXxrXBrfxDA++5+Lz3+PwA0u/sDZnYfgGHu/s1OztXjbPxB4ZgT8iwKbdPJbzGF3G1nQj74U2RPxxdM5eYwOrjzRtLut02UjeeaYD9vnpLJk0Pb0xTbypv/YpVpSmiDK0Mb5yL9aHgmbwmvcwq9H38W6l/PJMNvD90SQnRz4k59D6ISlGPjl6PqLwLwVQAbzaxtaeq/AHgAwKNmdg+APQA+192BCiFqS6cT393XAmjvF+SWdh4XQvRg8rk7rwPYnRe8aElyiSM3ZPLsN9J+WyhKblxwow2i3XMhPyU4MI5/kddNTPst2pXJMfHk9WQiNFBk3diQkPIA5fSfF+yANbRL8ANK2HFx0OkOU+KQwdPStnfIlqDhJjv1gNT06Qje1RdNAi5PEE2aPKLdeUKIkmjiC5FDcq/qDw7HXHj1X4U2qmoFWlhHjFc8Sht9Jr2YtrEq+qtJaVsjbeDhqL6hobTUi6TbtgbdllfyaUEeL6TdcBkpgwf7pG1Dyca5lDYmHQmltqbTZp6jwZm74upMPkDRiq0hv9xmkuMGHoZNn1BRDCtIjpGYM0l+vYPzn09I1RdClEQTX4gcookvRA7JZyIOIgS+YS7JMcEAJ41oIAN6abDBj5HPavfwtO0Sqhk98t207RWytSfTOX8YxvEndP6GKWnbB5TM4wCFyQ3dlvY7SKst01vTtl9QUs2JtF4xJiyI7KCdgG8G3+Tohkx+mez6sJyQ2PVxvYU/G34bn0T7xO2he0v2AiaEW95uDikM7wd24LxDd3whcogmvhA5JJfuvI5KM3EA2vzQxmokn+OK0I9V1BhJxntZwp4Xrt6Nl0j1nBXUdM5N96twjj8imV1l/YKDZ/SQTG4I0YXzKKkdV80K1cCTDU4vz03brqIkIMco7O4fgs/ua1SfIKr6f0syp+2P47iT5FDlC2RxYBjJ74d+SVB6j/iWdh+584QQJdHEFyKHaOILkUNyaeMzMTEE58GP4Z/s+1xM8v7Q71Mk9w9tbFtuDL6tAZQFpA9lqBiRdkvGFd1jfL1tSzL5gufTfs20wLA32Pi8K/FDkuPOOk5GGncariT/20hKsBlz5/M54+t8hWReQgjDBUdFx5z7/F5x6b843vMJ2fhCiJJo4guRQ3IZucdunQ9DW/CcJXCKfFaprw79dnbQRlW4sSeUxlpE6j2rpdHlyIGC/UKo2lxy011F6v2ahWm/E+QHPBnOceXWTOZK3tMHpv3230Fj/Ena1o/8mGxOjQm2Twv1C2n7wNXBb6Tdik0hUpKGi5BvJHH9sXv2NeQb3fGFyCGa+ELkkFyq+mdFbRGcbCPsoUnyvnHUXSy1tZ3kt0Mbp+f7dGjjwrdsEsTov6/QIP93CGObTAnpaL9OojbHMc7YmrZxTjuOJvy7UK7rs2QHvBaW2ufT8QF6fFOI3PttWtb/ypG0bSWZICdpjK+k3bCQXDHNYbmeUiMmOQ3jZh5+Cy4ObdEcPB/QHV+IHKKJL0QO0cQXIofkPnIvwrb7gtDGUX2Un+KsX89GkmPBQLZPQ65NcLVqLt81KLjA9tLFJwxJ2zipxiNkM88KtvUZKrUVIw/5tXGCysuCb/KajZn867QpyWXBu+5iSNmn6E3dHXLzjyJju9+4TF75WNpvEp1jR7Dxefz8Os+q1k2uyoFhLSMc9ngqErlnZv3N7DUz22Bmm83sL4qPTzKzV81sm5k9YmZ9OzuXEKJnUI6qfwrAEnefjcKi91IzWwDgWwC+7e5TUaizeE/1himEqCTl1M5zZHsfLir+OYAlAL5UfPxBAH8O4LuVH2L3iEku2Nu0hHa2PB+i5xaTvC6c48skP03y3aEfbwyJG0pYBY5uI1bvebPJieDPu2YX9futcH5Sv50+3UtD3vtXyHyYGc7/TyR/heRHNqb9WIUPQX0JH1I+/mFNadv7dJIZQafeQs+7jNx+o2am/caSz/Tn4dpsTvHw4+apk3Tt3qbad4eyFvfMrE+xUu5BAKtQSD/Y4u5t3+N9AMa293whRM+irInv7qfdfQ6AcSiEPMeS6kA7CYvMbJmZNZhZQ6l2IUTt6ZI7z91bAKxBYcF7iJm1KZPjcPbicNtzlrv7PHePC9xCiDrRqTvPzEYC+NjdW8xsAIDnUFjYuxvA4+7+sJl9D8Bb7v63nZyrfu48ygw5igzo+MvHufNDSvwkZJfDfoPZmti7wRxNatg1hjZecOFw3snBzfUehezetiltu2I29aOFiIaQcWQXLWBEtyLbbLyWcfXItN+pWzN5/D+mbT+idZQ/pnWUi8el/cbSgkjzHWnbFdQ2jLZUtrya9nuWduu9FPRKXm+hvJ74BepILNjAWUvbKwTQBcpx55UTqz8GwINm1geFefKouz9lZm8DeNjM/jsKIejfP6fRCiFqRjmr+m8BuLbE4ztxdgZqIUQvIJ+Re58gOfjb7ib9OyblYM8fu+KCJo59ZC9MCUnmONf9hLQpOT8Pa2NI3P/v6PwXDUvb9pJKf5h8hxOeSfutoPC824J6vJJ8XbfSQHYPSvvdTDbB6/vStoXU9yTZEheHQgBbrsnkpWE75Ae/l8nr6HVNCzbSEVKPV4R64AOpyAHn74hmFl/6stB2AL0L5dwTQpREE1+IHJLLRBxT9mTy9tDGq70xEQev0G8g+aoQBraT1PsYIcaablPIVz2TNtWw9j0pVGvlfHy7rkvbpr6cySfo4h8dSvt9lsyd4BjAXHJLbKPdLG/PSvsNoowdB0P9qy1Uy6offcv2/E7a7w5yG2yanLZ9TPm2b6CSXCfDyvcm8iBMC+WP15KcJPCIoZ200edAzAHOdt15kpVDd3whcogmvhA5RBNfiByST3deB3Bei7hLizco3Evyk6EfR/8FD1iyqPKz0MbJIbgMVywLNZHkGWPSto/IR3iUnDobQyLL8bRQ0LonbWslFx57Ej9amvYbRc87eSptO0HrEtspWu+u4PbjRBkxWGTA9Zn8Pi24xDoAu8nm3xReC+fq5/WWdWG3yZmY1L8XI3eeEKIkmvhC5BCp+l1gMcmc2i3m5nuJ5JgTn/Psx4i/mLeujT8Mx4+QfGko6fslUrmbyf/4y6CKzyJV/FNpUzLGYeTCu2BX2m8m2UKxau8mirRrphDIicG/OYfeoJ/PTtsmU/KQyynhSNMbab/Hx2dyv39O2zjqjr1y0c3KbtzrQ+jeOra1Yj2zHujek6ovhCiJJr4QOUQTX4gcIhu/Az4RjtlTtITkG4NF9df0Ku8KScefJl/fuBBGS1GuYO9biEJNkns+GNrup2QZfTikNvSbQXLYMJfUm9tLoawDwy7BGRTr+04wmk+R7T6eMppsCwntea3ks2Ec/NruIZfg0yGk1sjObmxN29jG5/c3Jgd9h9dKQgaWgZRp5Xj0zwY3aU9ANr4QoiSa+ELkEKn6XYBz0bELL5Zj4s1jN4Q2jlTbgvIIqe6SMtZhg19S/pnV2fgLz+XAZoxO2+ayakuPD4u7ED+fyXv+IW27+ouZ3PhQJsedgF+mXXLPhEG2kv/NDtP5wjk4aUl8nQcoCcggUuEPBTfcQTJNWoOq3xILLPRwpOoLIUqiiS9EDpGq3wU48osXga8P/Ti3W0zRzavrIXcFOCCN80TEMlysccfIwE+SHJwGCZTq7ixzgQLhQJm88VIo13U9hevZhrRtP9k/++n2sjNEvh2mVfLPht1Im8kjsohcLD8NiUlG0bcq5sfbS3bScLKRjoYqw5zTDzERx1b0KqTqCyFKookvRA7RxBcih+Qy2WZ3YQ8QB7FFG5zt5/jLyq65FR1cK56TiXY9wzv8/iPJsbYZm7QxQnEQWYjNtDvv5hC1NorC7i4MPs13v5TJrVRe65ZQB+B9qkX2zTCOkR9l8mnKijo39HuOoiFbg32+gOz6Jkrm+UaoUT6W3IVjwofWnxZq1g5I2xASi/QWyr7jF0tlv2FmTxWPJ5nZq2a2zcweMbO+nZ1DCNEz6Iqq/w2kmYy+BeDb7j4VwGEA91RyYEKI6lGWqm9m4wD8LoC/BPAnZmYo7FNpU+geBPDnAL5bhTH2SA6RT21ySHIxktxLb0xM23aSy2pY8Le9j3OH3YBcxTQWaL2A/JF9wvjfInX806T2756T9vuYcvifWpK2XUuq/3P0+OnwIleRfH8Y4xqqnjtrZSY/Ga515vlMjtWJm8kM2EauxC+EhIovkW+14Xh6P5w1g54YKvX2Vsq9438HBROs7R0YDqDF3dv2Qu1DGtEqhOjBdDrxzewzAA66+3p+uETXksE5ZrbMzBrMrKFUuxCi9pSj6i8CcIeZ3Y5C0NglKGgAQ8zswuJdfxyA/aWe7O7LASwHen/knhDnC10K2TWzxQD+k7t/xsweA/C4uz9sZt8D8Ja7R69RfH6vnvhsJ5P3J3GNAWnEZ0cll2M479s4d2jDXHKtKaEf/+KHHJeJu5CTaEZPFr+2/eEWMom2CW6n2uDv/W7ab/M/ZXLMq/8AyTeRvDb047aYF4PfA/7M3kP7xLthK78Jp9HjqXbI7n9GYaFvOwrf4e930l8I0UPoUgCPu68BsKYo7wQwv/JDEkJUG+3O6yasKoVUdInqHNV33pH3L6GNg8A4iUYs5cVEVwqlpkt22YWqU0kyi6bQ9gckt5AcqmTjOBUGaAkq8BnaQfcLUpVHhH6cAySWImPTgs2KnSGCcC+5SJtDaSyOPDmB7sHBhpVwuVYb7c4TQpREE1+IHKJNOt2E80nEHHCsHo8Ibazed7S/4xT/JMeyTURMm80qPSfYeDy4EMbGRIEEfyk+IB37QMhycTklFzwV9GhKs4d+pN7HUlv8tAFht9Ahymd+CZkVR0KtseR97KDqLZtBXdlb0xvU+66iO74QOUQTX4gcookvRA6RO68KsOspVlHmqL6rQ9tGkjlA4rXQjyPVQsXo5Hmcw/8roR9vvLgptHFihSV0a1gf1hqGUh2u10KRgN8n+VGSB4fc/E0UJhjdhT8leQIlx9zRkvbbQX7LY3vTtnLdoh3CSTt6YFnsiNx5QoiSaOILkUOk6leZUJ3qrCi5coguMA5+mxAybFxBO1HYY3d5OMctJO8IPsfPUYIQNhfGTUz7Dd6VyXvSpqQCb0eRb6NIviTkwWsgs2AStT0UfHH82t6EkKovhCiJJr4QOUQTX4gcopDdKtMVm54TZbJdHM/BeeWnB9fWRJIfIzmYz0mo7MiQ9POvSebc/Gt3pf049+a2cH4ug8fJMWIei77XZbK/nra1kuvsQ9rWGGsOhFJ6ogx0xxcih2jiC5FD5M7rhVxGUWzzQ0mqGZSk4uRbmbw+JMy7iXT9uPlvAcmcRj7m3GN3YSyjxO48ji6MbsXrxmTy3pCgcASV0JpCJs3+kMGEzYxgLfRMoo+Xcv+fZTN1A7nzhBAl0cQXIodI1a8j/cLxqZK9cJaOfTNtSmkZl7YdodC4K2gTzY6H035UOPasjKk8jnkk/03o93WSV4W2VpLZXIg6KG9aWhDaPr4xk7fQCv+lIWHH+pXoXcTsLIdK9uo2UvWFECXRxBcih2jiC5FDZOP3AuJaAHm5sCgYxsOogiGX5J4ctsWxHR9yV+J2CvMzsq1j2Sl24f0otLEZzt6rdWifIeGYgxI5V2hz2Ysj+aQcG7+skF0z2wXgGAoRl63uPs/MhgF4BIUo0V0APu/uh9s7hxCi59AVVf9md5/j7m0LvfcBWO3uUwGsLh4LIXoBZan6xTv+PHc/RI9tBbDY3RvNbAyANe4eKzXF80jVrwBchmtBUHubyA6YQbt+Ds1M++2jjBXBI4hrSOYUeStCv1tJDnuF8BzJnI6/Ep6sGCX4Ucle+aWS7jwH8JyZrTezZcXHRrt7Y/FCjUiTqQghejDlbstd5O77zWwUgFVmtqXTZxQp/lAs67SjEKJmlHXHd/f9xf8HATyBQrBXU1HFR/F/rObU9tzl7j6P1gaEEHWmUxvfzAYCuMDdjxXlVQD+Gwr5Gpvd/QEzuw/AMHf/Zifnko1faS5KDxdSlooNtBXuw5Cxcxjln48JMP8DyRxS+6vQj6tVHwtt0UUoakel3HmjATxhZm39/9HdnzGzdQAeNbN7UEiy+rlzGawQonZ0OvHdfSeA2SUeb0aapVkI0UtQ5F4vhHJXnFWimzfycW66VpTPSJJvIDnuwGNXX6iSLRdbHdHuPCFESTTxhcghmvhC5BDZ+NUmLp92xdjuBhwSy+GwcecbrwVMCm0csstrCNFw3EWyatb1HGTjCyFKookvRA6Rqp9TuKTW4NDGrjiqcIXVoR8n7NxZiUGJiiBVXwhREk18IXKIVP1qwCFtJ+s2imQY8Y3n5AmxrBVX5+VV/f6h38QOrr2hw5GJaiJVXwhREk18IXKIJr4QOUQ2fk7hSL6QoyMpf307yT8P/S4l+UglBiUqgmx8IURJNPGFyCHlZtkV5xmcI+90aONEH9s6OIfstt6L7vhC5BBNfCFyiCa+EDlE7rwqwL+mZ+o2iu7Dtel4p94Vod+Odp4Tnydqi9x5QoiSaOILkUPkzqsCvVG9Z9pLC3gqHE8g+Whok6rfsynrjm9mQ8zsJ2a2xczeMbOFZjbMzFaZ2bbi/6HVHqwQojKUq+r/LwDPuPsMFMppvQPgPgCr3X0qClmZ7qvOEIUQlaacarmXoJBXYbJTZzPbCmCxuzcWy2SvcffpnZwrF6v65TI+HO8t2av6DA/HzSV7nZ2wY38VxiLOnUqt6k8G8B6A/2dmb5jZ3xfLZY9298bihRqRJnURQvRgypn4F6KQbPW77n4tgOPoglpvZsvMrMHMGro5RiFEhSln4u8DsM/dXy0e/wSFH4KmooqP4v+DpZ7s7svdfZ67z6vEgIUQ506n7jx3P2Bme81surtvBXALgLeLf3cDeKD4f0VVR3oeUi+bPtKeTR+RTX/+UFbIrpnNAfD3KERm7gTwhyhoC48C+ASAPQA+5+7vd3IeLe4JUWXKWdxTrL4Q5xmK1RdClEQTX4gcookvRA7RxBcih2jiC5FDNPGFyCGa+ELkkFon4jgEYDeAEUW5nvSEMQAaR0TjSOnqOCZ03qXGATy/uahZQ71j93vCGDQOjaNe45CqL0QO0cQXIofUa+Ivr9N1mZ4wBkDjiGgcKVUZR11sfCFEfZGqL0QOqenEN7OlZrbVzLabWc2y8prZD8zsoJltosdqnh7czMab2QvFFOWbzewb9RiLmfU3s9fMbENxHH9RfHySmb1aHMcjZhYrY1VrPH2K+Ryfqtc4zGyXmW00szfb0sTV6TtSk1T2NZv4ZtYHwP8B8GkAMwF80cxm1ujyPwSwNDxWj/TgrQD+1N2vBLAAwNeL70Gtx3IKwBJ3nw1gDoClZrYAwLcAfLs4jsMA7qnyONr4Bgop29uo1zhudvc55D6rx3ekNqns3b0mfwAWAniWju8HcH8Nrz8RwCY63gpgTFEeA2BrrcZCY1gB4NZ6jgXAxQBeB3ADCoEiF5b6vKp4/XHFL/MSAE8BsDqNYxeAEeGxmn4uAC4B8C6Ka2/VHEctVf2xSNPM7Ss+Vi/qmh7czCYCuBbAq/UYS1G9fhOFJKmrUCh+2+LubRW0avX5fAfAN5FVHhtep3E4gOfMbL2ZLSs+VuvPpWap7Gs58UulA8qlS8HMBgF4HMC97h7LztUEdz/t7nNQuOPOB3BlqW7VHIOZfQbAQXe+pIWVAAABfklEQVRfzw/XehxFFrn7dSiYol83s5tqcM3IOaWy7wq1nPj7kBaPGYf6Jm4tKz14pTGzi1CY9D9295/WcywA4O4tANagsOYwxMza9m/U4vNZBOAOM9sF4GEU1P3v1GEccPf9xf8HATyBwo9hrT+Xc0pl3xVqOfHXAZhaXLHtC+ALAFbW8PqRlSikBQdqlB7czAzA9wG84+7/s15jMbORZjakKA8A8NsoLCK9AOAPajUOd7/f3ce5+0QUvg/Pu/uXaz0OMxtoZoPbZAC3AdiEGn8u7n4AwF4zaytF15bKvvLjqPaiSVikuB3Ar1GwJ/+shtd9CEAjgI9R+FW9BwVbcjWAbcX/w2owjk+ioLa+BeDN4t/ttR4LgGsAvFEcxyYA/7X4+GQArwHYDuAxAP1q+BktBvBUPcZRvN6G4t/mtu9mnb4jcwA0FD+bJwEMrcY4FLknRA5R5J4QOUQTX4gcookvRA7RxBcih2jiC5FDNPGFyCGa+ELkEE18IXLI/wfFMdxJ9E75IgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "combined text:  0 original sentence:  this yellow and red flower has many densely layered rounded petals.\n",
      " nn_sentences:  ['a flower with long and narrow petals that are orange.\\n', \"this flower sits at right angles to it's stem with two sharp orange petals above a purple petal and a longer orange petal.\\n\"]\n",
      "\n",
      "combined text:  1 original sentence:  this flower is yellow in color, with petals that are wavy and ruffled.\n",
      " nn_sentences:  ['this purple flower has small curled petals and green sepal.\\n', 'the flower has petals that are purple and white with purple filaments.\\n']\n",
      "\n",
      "combined text:  2 original sentence:  this flower is purple in color, and has petals that are ruffled and thin.\n",
      " nn_sentences:  ['the flower is made of pink petals with pink filaments and black anthers.\\n', 'the petals on this flower are purple with purple veins.\\n']\n",
      "\n",
      "combined text:  3 original sentence:  the bright orange, almond shaped petals have dark red spots and the stamen are orange.\n",
      " nn_sentences:  ['the petals on this flower are yellow and surround the yellow stamen in the center\\n', 'this flower has four wide and very smooth pink and yellow petals.\\n']\n",
      "\n",
      "combined text:  4 original sentence:  the flower has yellow and red petals with yellow stamen.\n",
      " nn_sentences:  ['this flower has a great many very thin yellow petals and a grouping of round yellow pistils at the center.\\n', 'this flower has petals that are yellow and are very thin\\n']\n",
      "\n",
      "combined text:  5 original sentence:  this flower has petals that are white with a white stigma.\n",
      " nn_sentences:  ['this purple color flower has the simple row of petals arranged in the circle with the red color pistils at the center\\n', 'this flower has pointy green petals as its main feature\\n']\n",
      "\n",
      "combined text:  6 original sentence:  leves aregreen in color,petals are light pink in color\n",
      " nn_sentences:  ['the petals on this flower are red with white stamen.\\n', 'broad purple oval petals with patches of yellow and white stamen.\\n']\n",
      "\n",
      "combined text:  7 original sentence:  the petals of the flower are pink and purple in color and have a brown stem attached to the bud.\n",
      " nn_sentences:  ['this flower is white and yellow in color, and has petals that are ruffled and wavy.\\n', 'this flower has rounded and very smooth pink petals with yellow accents.\\n']\n",
      "\n",
      "combined text:  8 original sentence:  this flower has bright purple petals, blue filaments, white pistils, and yellow stamen.\n",
      " nn_sentences:  ['this flower has several protruding stamen and four wide, rounded pink petals.\\n', 'this flower is purple in color, with petals that are small stars.\\n']\n",
      "\n",
      "combined text:  9 original sentence:  a golden and orange bell shaped flowers with a long stigma.\n",
      " nn_sentences:  ['the flower on this particular picture has petals as well as a sepal.\\n', 'the petals on this flower are red with white stamen.\\n']\n",
      "\n",
      "combined text:  10 original sentence:  this flower is plain white with big petal and a small stamen in the middle.\n",
      " nn_sentences:  ['the petals of this flower are white and yellow with a short stigma\\n', 'the flower has several bright yellow petals still not fully bloomed.\\n']\n",
      "\n",
      "combined text:  11 original sentence:  this flower has pale pink sepals and long flowers with small white petals.\n",
      " nn_sentences:  ['unusual flower with veined light green sepals and a petal that looks like a donut. magenta and white stamen.\\n', 'this flower is white and purple in color, with petals that are multi colored.\\n']\n",
      "\n",
      "combined text:  12 original sentence:  this flower has petals that are yellow and has orange shading\n",
      " nn_sentences:  ['this bright yellow flower has petals that overlap each other.\\n', 'unusual flower with veined light green sepals and a petal that looks like a donut. magenta and white stamen.\\n']\n",
      "\n",
      "combined text:  13 original sentence:  this flower has a wheel-like configuration of heart-shaped white petals with yellow at their base.\n",
      " nn_sentences:  ['this flower has soft and smooth pink petals with accents of white and yellow.\\n', 'this flower is yellow in color, with petals that are wavy.\\n']\n",
      "\n",
      "combined text:  14 original sentence:  this flower has petals that are pink with dark pink tips and yellow stigma.\n",
      " nn_sentences:  ['broad purple oval petals with patches of yellow and white stamen.\\n', 'this flower has large peach petals and a sage green pedicel.\\n']\n",
      "\n",
      "combined text:  15 original sentence:  the petals of this flower are green with a long stigma\n",
      " nn_sentences:  ['the flower has petals that are purple and white with purple filaments.\\n', 'this is a yellowish orange flower with many thin petals and a green, almost furry stem.\\n']\n",
      "\n",
      "combined text:  16 original sentence:  this flower has petals that are white and has a short style\n",
      " nn_sentences:  ['a light and park pink flower with yellow on the petals near the stamin.\\n', 'there are three petals that are next to each other that are purple around the edges and have a yellow grid-like pattern in the middle and then there is one larger petal on the opposite side that is white with light purple towards the middle.\\n']\n",
      "\n",
      "combined text:  17 original sentence:  this flower is purple in color, with petals that are spiral shaped.\n",
      " nn_sentences:  ['unusual flower with veined light green sepals and a petal that looks like a donut. magenta and white stamen.\\n', 'the petals on this flower round each other and basically form a ball, stem leaves resemble mug-wort.\\n']\n",
      "\n",
      "combined text:  18 original sentence:  the petals on this flower are red with no visible stamen.\n",
      " nn_sentences:  ['this flower has rounded and very smooth pink petals with yellow accents.\\n', 'broad purple oval petals with patches of yellow and white stamen.\\n']\n",
      "\n",
      "combined text:  19 original sentence:  the flower has round white and yellow thick petals pointing in every direction.\n",
      " nn_sentences:  ['a flower with long and narrow petals that are pink with yellow spots.\\n', 'this flower has petals that are pink and are folded together\\n']\n",
      "\n",
      "combined text:  20 original sentence:  this flower has petals that are white and has pink shading\n",
      " nn_sentences:  ['this flower is white and pink in color, with petals that have veins.\\n', 'this bright yellow flower has petals that overlap each other.\\n']\n",
      "\n",
      "combined text:  21 original sentence:  this red flower has many layered and pointed petals and yellow stamen.\n",
      " nn_sentences:  ['this flower is yellow in color, and has petals that are curled around the center.\\n', 'this flowers are so unique and such a sunny color, the shape of it is like a globe, i get another flush of these sun colored flowers, a real joy in the garden.\\n']\n",
      "\n",
      "combined text:  22 original sentence:  this flower has a white funnel shaped petal with a yellow ovary.\n",
      " nn_sentences:  ['this flowers are so unique and such a sunny color, the shape of it is like a globe, i get another flush of these sun colored flowers, a real joy in the garden.\\n', 'this flower has petals that are yellow with ruffled edges\\n']\n",
      "\n",
      "combined text:  23 original sentence:  this flower is red and white in color, and has petals that are green near the base of the ovary.\n",
      " nn_sentences:  ['this flower has petals that are purple and very stringy\\n', 'this flower has petals that are pink and has white stamen\\n']\n",
      "\n",
      "combined text:  24 original sentence:  a white flower with a yellow center with lot of leaves\n",
      " nn_sentences:  ['this flowers are so unique and such a sunny color, the shape of it is like a globe, i get another flush of these sun colored flowers, a real joy in the garden.\\n', 'this flower is white and pink in color, with petals that are striped.\\n']\n",
      "\n",
      "combined text:  25 original sentence:  this flower has petals that are overlapping with a burgundy layer under a layer of white petals with a burgundy spot.\n",
      " nn_sentences:  ['this flower has long spiky petals of orange and a purplish blue with spiky foliage.\\n', 'the pretty flower has two orange petals and one blue that make it look like some kind of bird.\\n']\n",
      "\n",
      "combined text:  26 original sentence:  there flowers have pink petals with stringy stamen in the center attached to brown pedicels.\n",
      " nn_sentences:  ['this flower has petals that are pink and has yellow stamen\\n', 'this flower is yellow and white in color, with petals that are layered vertically.\\n']\n",
      "\n",
      "combined text:  27 original sentence:  thick white smooth petals with pale yellow in on the inside of each petal revealing a star shaped orange pistil.\n",
      " nn_sentences:  ['this flower is yellow in color, with petals that are wavy.\\n', 'this flower has long prominent filaments with dark anthers rising out of bright orange petals with purple spots.\\n']\n",
      "\n",
      "combined text:  28 original sentence:  dark purple flowers with little white dots inside.\n",
      " nn_sentences:  ['this flower is yellow in color, and has petals that are very skinny.\\n', 'this flower has rounded and very smooth pink petals with yellow accents.\\n']\n",
      "\n",
      "combined text:  29 original sentence:  this flower has petals that are white with yellow stigma\n",
      " nn_sentences:  ['this flower with few stamen accented with orange anthers has overlapping, light pink petals.\\n', 'the bloom of the flower is purple in color with a stem that is green in color.\\n']\n",
      "\n",
      "combined text:  30 original sentence:  the pink petals are pointed and form a long bowl shape around yellow stamens.\n",
      " nn_sentences:  ['this flower has long prominent filaments with dark anthers rising out of bright orange petals with purple spots.\\n', 'this flower has yellow petals leaning down along with a green pedicel.\\n']\n",
      "\n",
      "combined text:  31 original sentence:  this beautiful star-shaped petals are pink in color with an inner trumpet-shaped row that are maroon in color with yellow anther filament in center.\n",
      " nn_sentences:  ['this flower has a large number of very thin petals that are purple in color and arranged upright.\\n', 'this flower is flat with numerous long thin orange petals.\\n']\n",
      "\n",
      "combined text:  32 original sentence:  this flower is yellow and black in color, with petals that are skinny and oval shaped.\n",
      " nn_sentences:  ['this flower is white and yellow in color, and has petals that are curled and wavy.\\n', 'this flower has a yellow center and layers of rounded orange petals.\\n']\n",
      "\n",
      "combined text:  33 original sentence:  this white and pink flower has pointed petals, a yellow pistil and a black pedicel.\n",
      " nn_sentences:  ['this flower has long prominent filaments with dark anthers rising out of bright orange petals with purple spots.\\n', 'the flower has many long peach colored pollen tubes.\\n']\n",
      "\n",
      "combined text:  34 original sentence:  this flower is pink in color, with petals that are closely wrapped around the center.\n",
      " nn_sentences:  ['this flower has three striped petals that are purple, red, and yellow, plus on solid colored petal.\\n', 'the petals of this flower are long and pink and the pedicel is green\\n']\n",
      "\n",
      "combined text:  35 original sentence:  this flower has a yellow center surrounded by layers of upturned long pink petals.\n",
      " nn_sentences:  ['this flower has many petals that are white shading into a greenish yellow.\\n', 'this dark purple flower has petals that grows vertically and two thick stamens.\\n']\n",
      "\n",
      "combined text:  36 original sentence:  this flower has petals that are pink with yellow stamen\n",
      " nn_sentences:  ['a yellow flower with multiple layers of yellow petals on a green sepal.\\n', 'a yellow flower with multiple layers of yellow petals on a green sepal.\\n']\n",
      "\n",
      "combined text:  37 original sentence:  this flower has four petals that are orange at the bottom and yellow at the top.\n",
      " nn_sentences:  ['the petals on this flower are orange with a purple pistil.\\n', 'the flower has petals that are green and spiky with pink filaments.\\n']\n",
      "\n",
      "combined text:  38 original sentence:  a one shaped flower with yellow and purple petals surrounding it's center.\n",
      " nn_sentences:  ['this flower has thick and sharply pointed petals in shades of yellow, red and indigo.\\n', 'the petals on this flower are orange with a purple pistil.\\n']\n",
      "\n",
      "combined text:  39 original sentence:  the flower has petals that are overlapping and yellow with large brown center.\n",
      " nn_sentences:  ['this flower has petals that are pink and has yellow shading\\n', 'flowers are alternately arranged,they are red in color\\n']\n",
      "\n",
      "combined text:  40 original sentence:  this unusual flower has long thin blue and white petals and a green center.\n",
      " nn_sentences:  ['the petals on this flower are red with white stamen.\\n', 'a small flower with string like yellow petals surrounding yellow stigma.\\n']\n",
      "\n",
      "combined text:  41 original sentence:  this white, blue and purple flower has pointed petals and green sepals.\n",
      " nn_sentences:  ['this flower is yellow in color, and has petals that are wavy.\\n', 'this flower has multiple pink with dark pink markings petals and pink with dark pink and yellow and white petals.\\n']\n",
      "\n",
      "combined text:  42 original sentence:  this flower is purple in color, with petals that are oval shaped.\n",
      " nn_sentences:  ['this flower has petals that are pink and are folded together\\n', 'this flower has soft and smooth pink petals with accents of white and yellow.\\n']\n",
      "\n",
      "combined text:  43 original sentence:  this flower is red in color, with petals that are pointed at the tips.\n",
      " nn_sentences:  ['the magenta flower with pale pink ridges on its petals has many yellow stamen and a yellow green center.\\n', 'this bright yellow flower has petals that overlap each other.\\n']\n",
      "\n",
      "combined text:  44 original sentence:  this flower has large orange petals that turn yellow towards the center.\n",
      " nn_sentences:  ['the flower has a smooth purple petal with a green pedicel\\n', 'broad purple oval petals with patches of yellow and white stamen.\\n']\n",
      "\n",
      "combined text:  45 original sentence:  this flower is pink and white in color, with petals that are multi colored.\n",
      " nn_sentences:  ['the flower has needle shaped green leaves with yellow colored petals hat are rounded and aclosed\\n', 'this flower is yellow in color, and has petals that are wavy and uneven.\\n']\n",
      "\n",
      "combined text:  46 original sentence:  this flower has white petals and green and purple stamen.\n",
      " nn_sentences:  ['this flower has pink and yellow petals with brown specks on them.\\n', 'this flower has long prominent filaments with dark anthers rising out of bright orange petals with purple spots.\\n']\n",
      "\n",
      "combined text:  47 original sentence:  this flower has petals that are orange and has yellow edges\n",
      " nn_sentences:  ['this flower has petals that are pink and are folded together\\n', 'this flower has petals that are white and dark pink.\\n']\n",
      "\n",
      "combined text:  48 original sentence:  the large flower has many oval shaped petals surrounding and bell shaped petal with large stamen.\n",
      " nn_sentences:  ['this flower has white furry petals with many green pointed ovaries.\\n', 'this flower has petals that are yellow and are folded together\\n']\n",
      "\n",
      "combined text:  49 original sentence:  this flower has petals that are a very light yellow color.\n",
      " nn_sentences:  ['this flower has petals that are yellow and are very thin\\n', 'this flower has soft and smooth pink petals with accents of white and yellow.\\n']\n",
      "\n",
      "combined text:  50 original sentence:  this flower has yellow and white petals and a green sepal and pedicel.\n",
      " nn_sentences:  ['this flower has three long yellow petals surrounding shorter yellow petals and pistil.\\n', 'this purple flower has small curled petals and green sepal.\\n']\n",
      "\n",
      "combined text:  51 original sentence:  a cream colored flower with an orange spot and a long stigma.\n",
      " nn_sentences:  [\"this flower sits at right angles to it's stem with two sharp orange petals above a purple petal and a longer orange petal.\\n\", 'this flower has red petals with black spots and has long white stamen on it\\n']\n",
      "\n",
      "combined text:  52 original sentence:  this flower has five smooth oblong petals that are white and yellow in color.\n",
      " nn_sentences:  ['this lush, yellow flower has a dense array of petals and similarly yellow stamen.\\n', 'the flower has diffrent multicolred petal tha are rounded in shape with large hanging stigma\\n']\n",
      "\n",
      "combined text:  53 original sentence:  this flower is all pink, with frilly and puffy petals with red highlights.\n",
      " nn_sentences:  ['this flower has petals that are yellow and are very thin\\n', 'the petals on this flower are orange with a purple pistil.\\n']\n",
      "\n",
      "combined text:  54 original sentence:  this flower has a cross-like configuration of bright yellow petals surrounding a small clump of stamen.\n",
      " nn_sentences:  ['this flower has yellow and pink petals with green pedicel as its main features\\n', 'this flower has petals that are yellow and folded together\\n']\n",
      "\n",
      "combined text:  55 original sentence:  a flower with large white petals a green stigma and yellow stamen.\n",
      " nn_sentences:  ['this flower has petals that are pink and very stringy\\n', 'curved pink stamen are surrounded by oval shaped pink and yellow petals that have subtle brown spots and lines on the innermost petals.\\n']\n",
      "\n",
      "combined text:  56 original sentence:  this flower has green pistil and smooth purple petals as its main features\n",
      " nn_sentences:  ['broad purple oval petals with patches of yellow and white stamen.\\n', 'this is a yellowish orange flower with many thin petals and a green, almost furry stem.\\n']\n",
      "\n",
      "combined text:  57 original sentence:  this flower is white and yellow in color, and has petals that are oval shaped.\n",
      " nn_sentences:  ['this flower has many stamen which point straight up and are dark in color, which are surrounded by many petals that are pointy ended and red-brown in color.\\n', 'a small flower with string like yellow petals surrounding yellow stigma.\\n']\n",
      "\n",
      "combined text:  58 original sentence:  this flower is yellow, white, and purple in color, with petals that are striped near the center.\n",
      " nn_sentences:  ['this flower has yellow petals as well as a green pedicel.\\n', 'this flower has rounded and very smooth pink petals with yellow accents.\\n']\n",
      "\n",
      "combined text:  59 original sentence:  a tan paper-like appearance with a white and red stigma.\n",
      " nn_sentences:  ['this flower has three long yellow petals surrounding shorter yellow petals and pistil.\\n', 'this flower has petals that are purple and has a big style\\n']\n",
      "\n",
      "combined text:  60 original sentence:  this flower is pink in color, and has petals that are ruffled.\n",
      " nn_sentences:  ['the flower has many long peach colored pollen tubes.\\n', 'this flower has petals that are yellow and are very thin\\n']\n",
      "\n",
      "combined text:  61 original sentence:  there are only five petals per flower and they are yellow closest to the center and white furthest from the center.\n",
      " nn_sentences:  ['the flower has petals that are purple and white with purple filaments.\\n', 'these delicate, rounded yellow petals conceal the pistil and stamens of the plant.\\n']\n",
      "\n",
      "combined text:  62 original sentence:  the petals are a light pink in color and have an uneven edge with an overall rounded shape.\n",
      " nn_sentences:  ['this is a yellowish orange flower with many thin petals and a green, almost furry stem.\\n', 'this flower is yellow in color, with petals that are wavy.\\n']\n",
      "\n",
      "combined text:  63 original sentence:  this flower has petals that are yellow and has brown stamen\n",
      " nn_sentences:  ['this flower has long prominent filaments with dark anthers rising out of bright orange petals with purple spots.\\n', 'this flower has petals that are pink with yellow lines and a single pink and white petal.\\n']\n",
      "\n",
      "combined text:  64 original sentence:  this flower has white petals as well as a green pedicel.\n",
      " nn_sentences:  ['this flat flower has long thin petals and a cluster of yellow stamen.\\n', 'the flower has many long peach colored pollen tubes.\\n']\n",
      "\n",
      "combined text:  65 original sentence:  this flower has large white petals and large yellow stamens.\n",
      " nn_sentences:  ['a yellow flower with multiple layers of yellow petals on a green sepal.\\n', 'a yellow flower with multiple layers of yellow petals on a green sepal.\\n']\n",
      "\n",
      "combined text:  66 original sentence:  this flower is made up of a double row of pink petals that all have a white strip down the center.\n",
      " nn_sentences:  ['this flower is brown, orange and black in color with sharp petals.\\n', 'this flower has rounded and very smooth pink petals with yellow accents.\\n']\n",
      "\n",
      "combined text:  67 original sentence:  this flower has smooth silky looking pink pedals with a touch color of white along the edges\n",
      " nn_sentences:  ['this flower is yellow and white in color, with petals that are layered vertically.\\n', 'this flower has rounded and very smooth pink petals with yellow accents.\\n']\n",
      "\n",
      "combined text:  68 original sentence:  the petals on this flower are white with green veins.\n",
      " nn_sentences:  ['curved pink stamen are surrounded by oval shaped pink and yellow petals that have subtle brown spots and lines on the innermost petals.\\n', 'broad purple oval petals with patches of yellow and white stamen.\\n']\n",
      "\n",
      "combined text:  69 original sentence:  this flower has petals that are pink and has red lines\n",
      " nn_sentences:  ['this flower has a ball of textured purple buds producing tiny flowers.\\n', 'the flower is pink with petals that are soft, smooth, thin and separately arranged around stamens\\n']\n",
      "\n",
      "combined text:  70 original sentence:  this particular flower has petals that are light green and yellow\n",
      " nn_sentences:  ['this flower has long prominent filaments with dark anthers rising out of bright orange petals with purple spots.\\n', 'this flower is white and purple in color, and has petals that are wavy and thin.\\n']\n",
      "\n",
      "combined text:  71 original sentence:  light pink petals with elongated maroon buds and white pistols\n",
      " nn_sentences:  ['the flower has white petals with light pink veins, it has yellow filaments, and anthers\\n', 'this exotic looking flower is a beautiful red with black spots.\\n']\n",
      "\n",
      "combined text:  72 original sentence:  there are several yellow stamen surrounded by bright red petals, making a very vibrant and open flower.\n",
      " nn_sentences:  ['broad purple oval petals with patches of yellow and white stamen.\\n', 'this flower has petals that are pink and has red stamen\\n']\n",
      "\n",
      "combined text:  73 original sentence:  this flower is red in color, and has petals that are in numbers and pointed.\n",
      " nn_sentences:  ['this is a large, white flower with large petals and yellow stamen.\\n', 'this flower is yellow in color, with petals that are wavy.\\n']\n",
      "\n",
      "combined text:  74 original sentence:  this bloom contains four rounded yellow petals and short tangled stamen centered around a black pistil.\n",
      " nn_sentences:  ['this flower has white petals as well as a purple pistil.\\n', 'this flower has petals that are white and has blue edges\\n']\n",
      "\n",
      "combined text:  75 original sentence:  this red flower has round pointed petals and yellow and red stamen.\n",
      " nn_sentences:  ['this bright yellow flower has petals that overlap each other.\\n', 'this flower has petals that are yellow and has black lines\\n']\n",
      "\n",
      "combined text:  76 original sentence:  this flower has five wide purple petals with yellow center accents.\n",
      " nn_sentences:  ['a flower with long and narrow petals that are pale yellow.\\n', 'this flower has rounded and very smooth pink petals with yellow accents.\\n']\n",
      "\n",
      "combined text:  77 original sentence:  the flower has petals that are pale yellow with a yellow shaped bell.\n",
      " nn_sentences:  ['this flower has petals that are yellow and has several layers\\n', 'this flower has petals that are orange and has black stamen\\n']\n",
      "\n",
      "combined text:  78 original sentence:  a flower with petals that are orange and curved outward.\n",
      " nn_sentences:  ['this flower has three striped petals that are purple, red, and yellow, plus on solid colored petal.\\n', 'this lush, yellow flower has a dense array of petals and similarly yellow stamen.\\n']\n",
      "\n",
      "combined text:  79 original sentence:  this flower has petals that are pink with purple lines\n",
      " nn_sentences:  ['this flower has red petals with black spots and has long white stamen on it\\n', 'a yellow flower with multiple layers of yellow petals on a green sepal.\\n']\n",
      "\n",
      "combined text:  80 original sentence:  the flower has petals that are red with pink stigma.\n",
      " nn_sentences:  ['this flower has a tall green stem with wavy petals in varying shades of yellow.\\n', 'the plant in the photo is spikey and has a pink plant.\\n']\n",
      "\n",
      "combined text:  81 original sentence:  this flower has red petals as well as a green pistil.\n",
      " nn_sentences:  ['this flower has long prominent filaments with dark anthers rising out of bright orange petals with purple spots.\\n', 'this flower has petals that are pink and has white stamen\\n']\n",
      "\n",
      "combined text:  82 original sentence:  the flower consists of multiple rows of yellow pedals surrounding brown stamen and stigma.\n",
      " nn_sentences:  ['this flower has wide spread purple petals with green near the pollen tube.\\n', 'this large blossom has rounded yellow petals which curl slightly outwards.\\n']\n",
      "\n",
      "combined text:  83 original sentence:  petals are white in color,inner petals are needle shpaed\n",
      " nn_sentences:  ['instead of opening itself up to the sun this flower with purple petals arcs its pedicel to show itself off at an angle.\\n', 'this flower is brown, orange and black in color with sharp petals.\\n']\n",
      "\n",
      "combined text:  84 original sentence:  this flower has a large funnel shape with uneven edges, a white coloring, and a green ovary.\n",
      " nn_sentences:  ['the flower has petals that are green and spiky with pink filaments.\\n', 'the petals on this flower are red with white stamen.\\n']\n",
      "\n",
      "combined text:  85 original sentence:  white stigma with a round petal that has a few hair like hooks around the edged space evenly apart\n",
      " nn_sentences:  ['this flower is pink and orange in color, with petals that are drooping down.\\n', 'this flower is orange and purple in color, and has petals that are oval shaped and spotted.\\n']\n",
      "\n",
      "combined text:  86 original sentence:  this flower is white and yellow in color, with petals that are wavy and ruffled.\n",
      " nn_sentences:  ['this flower is pink and orange in color, with petals that are drooping down.\\n', 'this flower has petals that are white and has a yellow style\\n']\n",
      "\n",
      "combined text:  87 original sentence:  the petals of this flower are orange with a long stigma\n",
      " nn_sentences:  ['this flower is purple and green in color, with petals that are pointed.\\n', 'this flower has one large pink petal and then a smaller purple petal with green streaks on each side of the large petal.\\n']\n",
      "\n",
      "combined text:  88 original sentence:  this simple flower has a bright yellow stamen and is complimented with pale white petals with pink tips.\n",
      " nn_sentences:  ['dark purple and yellow petal with the white and yellow middle\\n', 'the petals are rounded in shape and are yellow folded in color\\n']\n",
      "\n",
      "combined text:  89 original sentence:  this flower has small purple, blue, and yellow petals with small blue stamens.\n",
      " nn_sentences:  ['this flower has petals that are yellow and has black lines\\n', 'the flower has the flower has several bright yellow petals with gold colored stamen.\\n']\n",
      "\n",
      "combined text:  90 original sentence:  this flower has petals that are yellow and bell shaped\n",
      " nn_sentences:  ['the petals on this flower are mostly orange in color and the inner stamen is the color yellow.\\n', 'this flower has three long yellow petals surrounding shorter yellow petals and pistil.\\n']\n",
      "\n",
      "combined text:  91 original sentence:  the petals are large and red with some white petals and there are small stamen.\n",
      " nn_sentences:  ['this orange and dark purple spotted flower has curled petals and pale orange and burgundy stamen.\\n', 'this flower has lavender petals with maroon stripes and brown anther filaments.\\n']\n",
      "\n",
      "combined text:  92 original sentence:  the petals of this flower are red with a short stigma\n",
      " nn_sentences:  ['this particular flower has petals that are long and white with a yellow center\\n', 'this flower has petals that are red and are very small\\n']\n",
      "\n",
      "combined text:  93 original sentence:  this flower has petals that are red and has green stigma\n",
      " nn_sentences:  ['this flower has petals that are pink and has yellow stamen\\n', 'this peculiar flower has the look of humminbirds feeding off of it.\\n']\n",
      "\n",
      "combined text:  94 original sentence:  this flower has petals that are purple with white stamen\n",
      " nn_sentences:  ['this flower has petals that are yellow and folded together\\n', 'this flower has pointy long yellow petals and one sepal\\n']\n",
      "\n",
      "combined text:  95 original sentence:  a multi flower with color, with red, yellow and pink\n",
      " nn_sentences:  ['the bright yellow petals form a cup shape around bright yellow stamens.\\n', \"the round yellow petals of this flower are folded so that the viewer can't see any other parts of the flower.\\n\"]\n",
      "\n",
      "combined text:  96 original sentence:  this flower is white and yellow in color, with petals that have veins.\n",
      " nn_sentences:  ['this purple color flower has the simple row of petals arranged in the circle with the red color pistils at the center\\n', 'this flower has soft and smooth pink petals with accents of white and yellow.\\n']\n",
      "\n",
      "combined text:  97 original sentence:  the flower has white and purple petals and yellow stamens.\n",
      " nn_sentences:  [\"a bird shaped flower with large orange and purple petals protruding from it's light green and red pedicel.\\n\", 'these flowers has pale pink petals with spots of yellow\\n']\n",
      "\n",
      "combined text:  98 original sentence:  this flower has petals that are red and bell shaped\n",
      " nn_sentences:  ['this particular flower has petals that are long and white with a yellow center\\n', 'a large light purple flower with a yellow center and a long white stigma.\\n']\n",
      "\n",
      "combined text:  99 original sentence:  this flower has large floppy yellow leaves with pink splotches in the center.\n",
      " nn_sentences:  ['the petals of the flower are light pink in color with anthers that are hot pink.\\n', 'broad purple oval petals with patches of yellow and white stamen.\\n']\n",
      "\n",
      "combined text:  100 original sentence:  this flower has pink leaves with white at the bottom and a large green pistel and yellow stamen.\n",
      " nn_sentences:  ['this flower has petals that are pink and are folded together\\n', 'the flower has petals that are pointed and bright orange.\\n']\n",
      "\n",
      "combined text:  101 original sentence:  this flower is white and purple in color, and has petals that are spotted.\n",
      " nn_sentences:  ['this flower has long purple ribbed petals in a ring configuration.\\n', 'this flower has pale pink petals with veins and a white center.\\n']\n",
      "\n",
      "combined text:  102 original sentence:  this flower has petals that are red and has yellow style\n",
      " nn_sentences:  ['the petals on this flower are red with white stamen.\\n', 'this flower has petals that are pink and are folded together\\n']\n",
      "\n",
      "combined text:  103 original sentence:  this flower is pink and white in color, with petals that are very small.\n",
      " nn_sentences:  ['the petals on this flower are purple with purple veins.\\n', 'the petals on this flower are red with white stamen.\\n']\n",
      "\n",
      "combined text:  104 original sentence:  the bell shaped flower has petals that are soft, smooth and supported by green sepal with bunch of stamen sticking out\n",
      " nn_sentences:  ['the petals on this flower are red with white stamen.\\n', 'broad purple oval petals with patches of yellow and white stamen.\\n']\n",
      "\n",
      "combined text:  105 original sentence:  this flower has wide, slightly overlapping petals in white with pink accents.\n",
      " nn_sentences:  ['this purple flower has small curled petals and green sepal.\\n', 'this flower is pink and yellow in color, with petals that have veins.\\n']\n",
      "\n",
      "combined text:  106 original sentence:  this flower has very short white stamen surrounded by bright orange rounded petals with a smooth texture.\n",
      " nn_sentences:  ['this flower has a green receptacle and bright pink petals with smooth edges.\\n', 'this flower has multiple pink with dark pink markings petals and pink with dark pink and yellow and white petals.\\n']\n",
      "\n",
      "combined text:  107 original sentence:  this flower is white in color, and has petals that are uneven along the edges.\n",
      " nn_sentences:  ['this flower is white and yellow in color, and has petals that are curled and wavy.\\n', 'broad purple oval petals with patches of yellow and white stamen.\\n']\n",
      "\n",
      "combined text:  108 original sentence:  this flower is very light pink, with yellow stamen and a white pistil in the center.\n",
      " nn_sentences:  ['these flowers have white and purple petals that are semi round.\\n', 'the petals on this flower are red with white stamen.\\n']\n",
      "\n",
      "combined text:  109 original sentence:  this flower has petals that are white and folded together\n",
      " nn_sentences:  ['the flower has petals that are purple and white with purple filaments.\\n', 'this purple flower has small curled petals and green sepal.\\n']\n",
      "\n",
      "combined text:  110 original sentence:  this flower has bright yellow petals and pistil as its main features\n",
      " nn_sentences:  ['a flower with long and narrow pistils that are purple.\\n', 'this flower has petals that are yellow and are very thin\\n']\n",
      "\n",
      "combined text:  111 original sentence:  there are few very large overlapping pink petals surrounding a yellow stamen with a large green stigma.\n",
      " nn_sentences:  ['this flower has white petals with purple tips and a prominent stamen.\\n', 'this flower is yellow in color, and has petals that are wavy and uneven.\\n']\n",
      "\n",
      "combined text:  112 original sentence:  this flower is red in color, with petals that are oval shaped.\n",
      " nn_sentences:  ['this flower has petals that are orange and are very thin\\n', 'broad purple oval petals with patches of yellow and white stamen.\\n']\n",
      "\n",
      "combined text:  113 original sentence:  this flower is white in color, and has petals that are connected together\n",
      " nn_sentences:  ['this flower has purple-pink petals with yellow inner areas of the petal and dark red stripes on some of the petals.\\n', 'this flower has a green receptacle and bright pink petals with smooth edges.\\n']\n",
      "\n",
      "combined text:  114 original sentence:  the flower shown has pink pistil and small red rose colored petals\n",
      " nn_sentences:  ['this flower is white in color, with one large curled petal.\\n', 'broad purple oval petals with patches of yellow and white stamen.\\n']\n",
      "\n",
      "combined text:  115 original sentence:  this flower is orange in color, with petals that are wilted in appearance.\n",
      " nn_sentences:  ['this flower has multiple pink with dark pink markings petals and pink with dark pink and yellow and white petals.\\n', 'this flower has petals that are yellow and has black lines\\n']\n",
      "\n",
      "combined text:  116 original sentence:  the flower petals is spiked and lite purple and dark purple\n",
      " nn_sentences:  ['this flower has rounded and very smooth pink petals with yellow accents.\\n', 'the multiple blooms of this bloom are yellow and are upon a multi-leaf pedicel.\\n']\n",
      "\n",
      "combined text:  117 original sentence:  the alternating leaves with lots of green buds\n",
      " nn_sentences:  ['this flower has green petals as well as a green pedicel.\\n', 'this lush, yellow flower has a dense array of petals and similarly yellow stamen.\\n']\n",
      "\n",
      "combined text:  118 original sentence:  this flower has a ring arrangement of small pink petals with yellow pointed tips.\n",
      " nn_sentences:  ['broad purple oval petals with patches of yellow and white stamen.\\n', 'a flower with long and narrow petals that are orange.\\n']\n",
      "\n",
      "combined text:  119 original sentence:  this flower has bright pink oblong petals with darker pink spots and tall yellow stamen.\n",
      " nn_sentences:  ['the petals on this flower are red with white stamen.\\n', 'this flower is orange and blue in color, and has petals that are pointed at the tip.\\n']\n",
      "\n",
      "combined text:  120 original sentence:  this flower has long red petals with very pointed edges that are stacked one layer on top of the next.\n",
      " nn_sentences:  ['this flowers are so unique and such a sunny color, the shape of it is like a globe, i get another flush of these sun colored flowers, a real joy in the garden.\\n', 'this flowers are so unique and such a sunny color, the shape of it is like a globe, i get another flush of these sun colored flowers, a real joy in the garden.\\n']\n",
      "\n",
      "combined text:  121 original sentence:  this flower has red petals with a large lighter shaded area on the inside, and yellow and white stamen.\n",
      " nn_sentences:  ['this flower has large yellow petals with dark stripes leading towards the center.\\n', 'this flower has multiple pink with dark pink markings petals and pink with dark pink and yellow and white petals.\\n']\n",
      "\n",
      "combined text:  122 original sentence:  this flower has white petals and a yellow color leading to the pistil.\n",
      " nn_sentences:  ['this flower has yellow stamen and petals that are white with blue edges.\\n', 'this flower is yellow in color, with petals that are pointy.\\n']\n",
      "\n",
      "combined text:  123 original sentence:  the petals on this flower are orange with dark orange veins.\n",
      " nn_sentences:  ['this flower has large yellow petals with dark stripes leading towards the center.\\n', 'the petals on this flower are red with white stamen.\\n']\n",
      "\n",
      "combined text:  124 original sentence:  the flower is pink with petals that are soft, smooth and separately arranged around the pedicel\n",
      " nn_sentences:  ['curved pink stamen are surrounded by oval shaped pink and yellow petals that have subtle brown spots and lines on the innermost petals.\\n', 'this flower has petals that are pink and are folded together\\n']\n",
      "\n",
      "combined text:  125 original sentence:  the petals on this flower are purple with an elaborate pistil.\n",
      " nn_sentences:  ['this flower is white and pink in color, with petals that are striped.\\n', 'broad purple oval petals with patches of yellow and white stamen.\\n']\n",
      "\n",
      "combined text:  126 original sentence:  this flower has petals that are yellow with yellow stamen\n",
      " nn_sentences:  ['this particular flower has petals that are long and white with a yellow center\\n', 'this flower has yellow petals leaning down along with a green pedicel.\\n']\n",
      "\n",
      "combined text:  127 original sentence:  this flower has petals that are pink and has may layers\n",
      " nn_sentences:  ['this flower has petals that are yellow and are very thin\\n', 'this flower has three long yellow petals surrounding shorter yellow petals and pistil.\\n']\n",
      "*** end of testing ***\n",
      "Running GAN-CLS took 0:07:44\n"
     ]
    }
   ],
   "source": [
    "################ nn.py (NearestNeighbour) ###################\n",
    "\n",
    "class NearestNeighbor:\n",
    "    def __init__(self, dataset, source, cuda, ngf):\n",
    "        self.dataset = dataset\n",
    "        data = None\n",
    "        representation = None\n",
    "        labels = []\n",
    "        embeddings = []\n",
    "        path = ''\n",
    "        data_path = path + 'source_{}_nn_data.pl'.format(source)\n",
    "        labels_path = path + 'source_{}_nn_labels.pl'.format(source)\n",
    "        nbrs_path = path + 'source_{}_nn.pl'.format(source)\n",
    "        embeddings_path = path + 'source_{}_nn_embeddings.pl'.format(source)\n",
    "        self.model = gan_factory.generator_factory('vae', ngf, False)\n",
    "        if cuda:\n",
    "            self.model = self.model.cuda()\n",
    "        #self.model.load_state_dict(torch.load('./checkpoints/flowers_autoencoder/gen.pth'))\n",
    "\n",
    "        if os.path.exists(data_path):\n",
    "            print('start loading data for NN test {}'.format(data_path))\n",
    "            data = pickle.load(open(data_path, 'rb'))\n",
    "            labels = pickle.load(open(labels_path, 'rb'))\n",
    "            nbrs = pickle.load(open(nbrs_path, 'rb'))\n",
    "            embeddings = pickle.load(open(embeddings_path, 'rb'))\n",
    "        else:\n",
    "            print('start creating data for NN test {}'.format(data_path))\n",
    "            for i, sample in enumerate(dataset):\n",
    "                #print(\"**** iter i = \",i)\n",
    "                if data is None:\n",
    "                    data = sample['right_images'].numpy()\n",
    "                    data_var = Variable(sample['right_images'].float(), volatile=True)\n",
    "                    if cuda:\n",
    "                        data_var = data_var.cuda()\n",
    "                    representation = self.model.encoder_only(data_var).data.cpu().numpy()\n",
    "                    labels = sample['txt']\n",
    "                    embeddings = sample['right_embed']\n",
    "                else:\n",
    "                    data = np.append(data, sample['right_images'].numpy(), axis=0)\n",
    "                    data_var = Variable(sample['right_images'].float(), volatile=True)\n",
    "                    if cuda:\n",
    "                        data_var = data_var.cuda()\n",
    "                    representation = np.append(representation, self.model.encoder_only(data_var).data.cpu().numpy(),\n",
    "                                               axis=0)\n",
    "                    labels += sample['txt']\n",
    "                    embeddings = np.append(embeddings, sample['right_embed'].numpy(), axis=0)\n",
    "            nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(representation.reshape(-1, 228))\n",
    "            pickle.dump(data, open(data_path, 'wb'))\n",
    "            pickle.dump(labels, open(labels_path, 'wb'))\n",
    "            pickle.dump(nbrs, open(nbrs_path, 'wb'))\n",
    "            pickle.dump(embeddings, open(embeddings_path, 'wb'))\n",
    "        print('finish loading data for NN test')\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.nbrs = nbrs\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def get_text(self, samples, limit=-1):\n",
    "        text_results, _, _ = self.get_text_and_images_and_embedding(samples, limit)\n",
    "        return text_results\n",
    "\n",
    "    def get_text_and_images(self, samples, limit):\n",
    "        text_results, image_results, _ = self.get_text_and_images_and_embedding(samples, limit)\n",
    "        return text_results, image_results\n",
    "\n",
    "    def get_text_and_images_and_embedding(self, samples, limit=-1):\n",
    "        samples_embedding = self.model.encoder_only(samples).data.cpu().numpy().reshape(-1, 228)\n",
    "        if limit != -1:\n",
    "            samples_embedding = samples_embedding[:limit]\n",
    "        distances, indices = self.nbrs.kneighbors(samples_embedding)\n",
    "        text_results = [self.labels[index] for index in indices[:, 0]]\n",
    "        image_results = [self.data[index] for index in indices[:, 0]]\n",
    "        embedding_results = [self.embeddings[index] for index in indices[:, 0]]\n",
    "        return text_results, image_results, embedding_results\n",
    "    \n",
    "################ nn.py (NearestNeighbour) ends here ###################\n",
    "\n",
    "################ txt2image_dataset.py ###################\n",
    "\n",
    "class Text2ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, datasetFile, transform=None, split=0):\n",
    "        self.datasetFile = datasetFile\n",
    "        self.transform = transform\n",
    "        self.dataset = None\n",
    "        self.dataset_keys = None\n",
    "        self.split = 'train' if split == 0 else 'valid' if split == 1 else 'test'\n",
    "        self.h5py2int = lambda x: int(np.array(x))\n",
    "\n",
    "    def __len__(self):\n",
    "        f = h5py.File(self.datasetFile, 'r')\n",
    "        self.dataset_keys = [str(k) for k in f[self.split].keys()]\n",
    "        length = len(f[self.split])\n",
    "        f.close()\n",
    "\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.dataset is None:\n",
    "            self.dataset = h5py.File(self.datasetFile, mode='r')\n",
    "            self.dataset_keys = [str(k) for k in self.dataset[self.split].keys()]\n",
    "\n",
    "        example_name = self.dataset_keys[idx]\n",
    "        example = self.dataset[self.split][example_name]\n",
    "\n",
    "        # pdb.set_trace()\n",
    "\n",
    "        right_image = bytes(np.array(example['img']))\n",
    "        right_embed = np.array(example['embeddings'], dtype=float)\n",
    "        wrong_image = bytes(np.array(self.find_wrong_image(example['class'])))\n",
    "        inter_embed = np.array(self.find_inter_embed())\n",
    "\n",
    "        right_image = Image.open(io.BytesIO(right_image)).resize((64, 64))\n",
    "        wrong_image = Image.open(io.BytesIO(wrong_image)).resize((64, 64))\n",
    "\n",
    "        right_image = self.validate_image(right_image)\n",
    "        wrong_image = self.validate_image(wrong_image)\n",
    "\n",
    "        txt = np.array(example['txt']).astype(str)\n",
    "        class_ = np.array(example['class']).astype(str)\n",
    "\n",
    "        sample = {\n",
    "                'right_images': torch.FloatTensor(right_image),\n",
    "                'right_embed': torch.FloatTensor(right_embed),\n",
    "                'wrong_images': torch.FloatTensor(wrong_image),\n",
    "                'inter_embed': torch.FloatTensor(inter_embed),\n",
    "                'txt': str(txt),\n",
    "                'class': str(class_)\n",
    "                 }\n",
    "\n",
    "        sample['right_images'] = sample['right_images'].sub_(127.5).div_(127.5)\n",
    "        sample['wrong_images'] =sample['wrong_images'].sub_(127.5).div_(127.5)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def find_wrong_image(self, category):\n",
    "        idx = np.random.randint(len(self.dataset_keys))\n",
    "        example_name = self.dataset_keys[idx]\n",
    "        example = self.dataset[self.split][example_name]\n",
    "        _category = example['class']\n",
    "\n",
    "        if _category != category:\n",
    "            return example['img']\n",
    "\n",
    "        return self.find_wrong_image(category)\n",
    "\n",
    "    def find_inter_embed(self):\n",
    "        idx = np.random.randint(len(self.dataset_keys))\n",
    "        example_name = self.dataset_keys[idx]\n",
    "        example = self.dataset[self.split][example_name]\n",
    "        return example['embeddings']\n",
    "\n",
    "\n",
    "    def validate_image(self, img):\n",
    "        img = np.array(img, dtype=float)\n",
    "        if len(img.shape) < 3:\n",
    "            rgb = np.empty((64, 64, 3), dtype=np.float32)\n",
    "            rgb[:, :, 0] = img\n",
    "            rgb[:, :, 1] = img\n",
    "            rgb[:, :, 2] = img\n",
    "            img = rgb\n",
    "\n",
    "        return img.transpose(2, 0, 1)\n",
    "\n",
    "################ txt2image_dataset.py ends here ###################\n",
    "\n",
    "################ utils.py ###################\n",
    "\n",
    "class Concat_embed(nn.Module):\n",
    "    def __init__(self, embed_dim, projected_embed_dim):\n",
    "        super(Concat_embed, self).__init__()\n",
    "        self.projection = nn.Sequential(nn.Linear(in_features=embed_dim, out_features=projected_embed_dim),\n",
    "                                        nn.BatchNorm1d(num_features=projected_embed_dim),\n",
    "                                        nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
    "\n",
    "    def forward(self, inp, embed):\n",
    "        projected_embed = self.projection(embed)\n",
    "        replicated_embed = projected_embed.repeat(4, 4, 1, 1).permute(2, 3, 0, 1)\n",
    "        hidden_concat = torch.cat([inp, replicated_embed], 1)\n",
    "\n",
    "        return hidden_concat\n",
    "\n",
    "class Utils(object):\n",
    "    def __init__(self, cuda):\n",
    "        self.is_cuda = cuda\n",
    "\n",
    "    def cuda(self, variable):\n",
    "        return variable.cuda() if self.is_cuda else variable\n",
    "\n",
    "    @staticmethod\n",
    "    def smooth_label(tensor, offset):\n",
    "        return tensor + offset\n",
    "\n",
    "    @staticmethod\n",
    "    def save_checkpoint(netD, netG, dir_path, epoch):\n",
    "        path = dir_path #os.path.join(dir_path, subdir_path)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        torch.save(netD.state_dict(), '{0}/disc_{1}.pth'.format(path, epoch))\n",
    "        torch.save(netG.state_dict(), '{0}/gen_{1}.pth'.format(path, epoch))\n",
    "        \n",
    "    @staticmethod\n",
    "    def weights_init(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            m.weight.data.normal_(0.0, 0.02)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            m.weight.data.normal_(1.0, 0.02)\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "################ utils.py ends here ###################\n",
    "\n",
    "################ vae.py ###################\n",
    "\n",
    "class vae_encoder_generator(nn.Module):\n",
    "    def __init__(self, ngf):\n",
    "        super(vae_encoder_generator, self).__init__()\n",
    "        self.vae_encoder = vae_encoder(ngf)\n",
    "        self.vae_generator = vae_generator(ngf)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = self.vae_encoder(inp)\n",
    "        x = self.vae_generator(x)\n",
    "        return x\n",
    "\n",
    "    def generator_only(self, latent):\n",
    "        return self.vae_generator(latent)\n",
    "\n",
    "    def encoder_only(self, inp):\n",
    "        return self.vae_encoder(inp.cuda())\n",
    "\n",
    "\n",
    "class vae_generator(nn.Module):\n",
    "    def __init__(self, ngf):\n",
    "        super(vae_generator, self).__init__()\n",
    "        self.image_size = 64\n",
    "        self.num_channels = 3\n",
    "        self.noise_dim = 100\n",
    "        self.embed_dim = 1024\n",
    "        self.projected_embed_dim = 128\n",
    "        self.latent_dim = self.noise_dim + self.projected_embed_dim\n",
    "        self.ngf = ngf\n",
    "\n",
    "        # self.projection = nn.Sequential(nn.Linear(in_features=self.embed_dim, out_features=self.projected_embed_dim),\n",
    "        #     nn.BatchNorm1d(num_features=self.projected_embed_dim), nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
    "\n",
    "        # based on: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
    "        self.netG = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.latent_dim, self.ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 8),\n",
    "            nn.ReLU(True), # state size. (ngf*8) x 4 x 4\n",
    "\n",
    "            nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 4),\n",
    "            nn.ReLU(True), # state size. (ngf*4) x 8 x 8\n",
    "\n",
    "            nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 2),\n",
    "            nn.ReLU(True), # state size. (ngf*2) x 16 x 16\n",
    "\n",
    "            nn.ConvTranspose2d(self.ngf * 2, self.ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(self.ngf, self.num_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (num_channels) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, latent_vector):\n",
    "        # projected_embed = self.projection(embed_vector).unsqueeze(2).unsqueeze(3)\n",
    "        # latent_vector = torch.cat([projected_embed, z], 1)\n",
    "        latent_vector = latent_vector.view(-1, self.latent_dim, 1, 1)\n",
    "        #print(\"**** latent_vector is cuda = \",latent_vector.cpu().is_cuda)\n",
    "        output = self.netG(latent_vector.cpu())\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class vae_encoder(nn.Module):\n",
    "    def __init__(self, ngf):\n",
    "        super(vae_encoder, self).__init__()\n",
    "        self.image_size = 64\n",
    "        self.num_channels = 3\n",
    "        self.embed_dim = 1024\n",
    "        self.noise_dim = 100\n",
    "        self.projected_embed_dim = 128\n",
    "        self.latent_dim = self.noise_dim + self.projected_embed_dim\n",
    "        self.ngf = ngf\n",
    "\n",
    "        self.projection = nn.Sequential(nn.Linear(in_features=self.embed_dim, out_features=self.projected_embed_dim),\n",
    "            nn.BatchNorm1d(num_features=self.projected_embed_dim), nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
    "\n",
    "        # based on: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
    "        self.netE = nn.Sequential(\n",
    "            # state size. (num_channels) x 64 x 64\n",
    "            nn.Conv2d(self.num_channels, self.ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.Conv2d(self.ngf, self.ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.Conv2d(self.ngf * 2, self.ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.Conv2d(self.ngf * 4, self.ngf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.Conv2d(self.ngf * 8, self.latent_dim, 4, 1, 0, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        output = self.netE(images)\n",
    "        #print(output.is_cuda)\n",
    "        return output\n",
    "\n",
    "\n",
    "class vae_discriminator(nn.Module):\n",
    "    def __init__(self, remove_noise):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.image_size = 64\n",
    "        self.num_channels = 128\n",
    "        self.embed_dim = 1024\n",
    "        if remove_noise:\n",
    "            self.projected_embed_dim = 228\n",
    "            self.noise_dim = 0\n",
    "        else:\n",
    "            self.projected_embed_dim = 128\n",
    "            self.noise_dim = 100\n",
    "        self.B_dim = 128\n",
    "        self.C_dim = 16\n",
    "        self.minibatch_discriminator = minibatch_discriminator(self.num_channels, self.B_dim, self.C_dim)\n",
    "        #\n",
    "        self.netD_1 = nn.Sequential(\n",
    "            nn.Linear(self.projected_embed_dim + self.noise_dim, 228),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(228, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.netD_2 = nn.Sequential(\n",
    "            nn.Linear(128 + self.B_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = inp.view(-1, self.projected_embed_dim + self.noise_dim)\n",
    "        x = self.netD_1(x)\n",
    "        x = self.minibatch_discriminator(x)\n",
    "        x = self.netD_2(x)\n",
    "\n",
    "        return x.view(-1)\n",
    "\n",
    "################ vae.py ends here ###################\n",
    "\n",
    "################ gan_cls.py ###################\n",
    "\n",
    "class generator(nn.Module):\n",
    "    def __init__(self, remove_noise, variational):\n",
    "        super(generator, self).__init__()\n",
    "        self.image_size = 64\n",
    "        self.num_channels = 3\n",
    "        self.embed_dim = 1024\n",
    "        self.remove_noise = remove_noise\n",
    "        if remove_noise:\n",
    "            self.noise_dim = 0\n",
    "            self.projected_embed_dim = 228\n",
    "        else:\n",
    "            self.noise_dim = 100\n",
    "            self.projected_embed_dim = 128\n",
    "        self.latent_dim = self.noise_dim + self.projected_embed_dim\n",
    "        self.ngf = 64\n",
    "        self.variational = variational\n",
    "        self.mu = None\n",
    "        self.sd = None\n",
    "\n",
    "        self.projection = nn.Sequential(nn.Linear(in_features=self.embed_dim, out_features=self.projected_embed_dim),\n",
    "            nn.BatchNorm1d(num_features=self.projected_embed_dim), nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
    "\n",
    "        if variational:\n",
    "            self.en_mu = nn.Conv2d(self.projected_embed_dim, self.projected_embed_dim, 1, 1, 0)\n",
    "            self.en_sigma = nn.Conv2d(self.projected_embed_dim, self.projected_embed_dim, 1, 1, 0)\n",
    "            self.softplus = nn.Softplus()\n",
    "            self.en_mu.weight.data.normal_(0, 0.002)\n",
    "            self.en_mu.bias.data.normal_(0, 0.002)\n",
    "            self.en_sigma.weight.data.normal_(0, 0.002)\n",
    "            self.en_sigma.bias.data.normal_(0, 0.002)\n",
    "\n",
    "        # based on: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
    "        self.netG = nn.Sequential(nn.ConvTranspose2d(self.latent_dim, self.ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 8), nn.ReLU(True), # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ngf * 4),\n",
    "            nn.ReLU(True), # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ngf * 2),\n",
    "            nn.ReLU(True), # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(self.ngf * 2, self.ngf, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ngf), nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(self.ngf, self.num_channels, 4, 2, 1, bias=False), nn.Tanh()\n",
    "            # state size. (num_channels) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, embed_vector, z, noise):\n",
    "        return self.netG(self.encoder_only(embed_vector, z, noise))\n",
    "\n",
    "    def encoder_only(self, embed_vector, z, noise):\n",
    "        projected_embed = self.projection(embed_vector).unsqueeze(2).unsqueeze(3)\n",
    "        if self.variational:\n",
    "            self.mu = self.en_mu(projected_embed)\n",
    "            self.sd = self.softplus(self.en_sigma(projected_embed))\n",
    "            projected_embed = self.mu + self.sd.mul(noise)\n",
    "        if self.remove_noise:\n",
    "            latent_vector = projected_embed\n",
    "        else:\n",
    "            latent_vector = torch.cat([projected_embed, z], 1)\n",
    "        return latent_vector\n",
    "\n",
    "    def generator_only(self, latent_vector):\n",
    "        return self.netG(latent_vector)\n",
    "\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    def __init__(self, remove_noise):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.image_size = 64\n",
    "        self.num_channels = 3\n",
    "        self.embed_dim = 1024\n",
    "        if remove_noise:\n",
    "            self.projected_embed_dim = 228\n",
    "        else:\n",
    "            self.projected_embed_dim = 128\n",
    "        self.ndf = 64\n",
    "        self.B_dim = 128\n",
    "        self.C_dim = 16\n",
    "\n",
    "        self.netD_1 = nn.Sequential(# input is (nc) x 64 x 64\n",
    "            nn.Conv2d(self.num_channels, self.ndf, 4, 2, 1, bias=False), nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(self.ndf, self.ndf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(self.ndf * 2, self.ndf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(self.ndf * 4, self.ndf * 8, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True), )\n",
    "\n",
    "        self.projector = Concat_embed(self.embed_dim, self.projected_embed_dim)\n",
    "\n",
    "        self.netD_2 = nn.Sequential(# state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(self.ndf * 8 + self.projected_embed_dim, 1, 4, 1, 0, bias=False), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, inp, embed):\n",
    "        x_intermediate = self.netD_1(inp)\n",
    "        x = self.projector(x_intermediate, embed)\n",
    "        x = self.netD_2(x)\n",
    "\n",
    "        return x.view(-1, 1).squeeze(1), x_intermediate\n",
    "\n",
    "################ gan_cls.py ends here ###################\n",
    "\n",
    "################ gan_factory.py ###################\n",
    "\n",
    "class gan_factory(object):\n",
    "    @staticmethod\n",
    "    def generator_factory(type, ngf, remove_noise, variational=False):\n",
    "        if type == 'gan':\n",
    "            return generator(remove_noise, variational)\n",
    "        elif type == 'vae':\n",
    "            return vae_encoder_generator(ngf)\n",
    "\n",
    "    @staticmethod\n",
    "    def discriminator_factory(type, remove_noise):\n",
    "        if type == 'gan':\n",
    "            return discriminator(remove_noise)\n",
    "        elif type == 'vae':\n",
    "            return vae_discriminator(remove_noise)\n",
    "\n",
    "################ gan_factory.py ends here ###################\n",
    "\n",
    "################ trainer.py ###################\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, type, dataset, split, lr, diter, vis_screen, save_path, l1_coef, l2_coef, pre_trained_gen,\n",
    "                 pre_trained_disc, batch_size, num_workers, epochs, args, params_search=False):\n",
    "        self.config = args\n",
    "        self.cuda = torch.cuda.is_available()\n",
    "\n",
    "        self.generator = gan_factory.generator_factory(type, args.ngf, args.remove_noise_2, args.variational)\n",
    "        self.discriminator = gan_factory.discriminator_factory(type, args.remove_noise_2)\n",
    "\n",
    "        self.target_generator = gan_factory.generator_factory(args.target_type, args.ngf, args.remove_noise_2)\n",
    "        \n",
    "        if self.cuda:\n",
    "            self.generator = self.generator.cuda()\n",
    "            self.discriminator = self.discriminator.cuda()\n",
    "\n",
    "        if pre_trained_disc:\n",
    "            print('loading {} from {}'.format('discriminator', pre_trained_disc))\n",
    "            self.discriminator.load_state_dict(torch.load(pre_trained_disc))\n",
    "        else:\n",
    "            if not params_search:\n",
    "                print('creating fresh params for {}'.format('discriminator'))\n",
    "            self.discriminator.apply(Utils.weights_init)\n",
    "\n",
    "        if pre_trained_gen:\n",
    "            print('loading {} from {}'.format('generator', pre_trained_gen))\n",
    "            self.generator.load_state_dict(torch.load(pre_trained_gen))\n",
    "        else:\n",
    "            if not params_search:\n",
    "                print('creating fresh params for {}'.format('generator'))\n",
    "            self.generator.apply(Utils.weights_init)\n",
    "\n",
    "        if dataset == 'flowers_only':\n",
    "            self.dataset = Text2ImageDataset(self.config.flowers_dataset_path, split=0)\n",
    "            self.target_dataset = Text2ImageDataset(self.config.flowers_dataset_path, split=2)\n",
    "        else:\n",
    "            print('Dataset not supported, please select either birds, flowers or flowers_only.')\n",
    "            exit()\n",
    "\n",
    "        self.noise_dim = 100\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.lr = lr\n",
    "        self.beta1 = 0.5\n",
    "        self.num_epochs = epochs\n",
    "        self.DITER = diter\n",
    "\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "\n",
    "        self.data_loader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True,\n",
    "                                      num_workers=self.num_workers)\n",
    "        self.target_data_loader = DataLoader(self.target_dataset, batch_size=self.batch_size, shuffle=True,\n",
    "                                             num_workers=self.num_workers)\n",
    "\n",
    "        self.optimD = torch.optim.Adam(self.discriminator.parameters(), lr=self.lr, betas=(self.beta1, 0.999))\n",
    "        self.optimG = torch.optim.Adam(self.generator.parameters(), lr=self.lr, betas=(self.beta1, 0.999))\n",
    "\n",
    "        self.save_path = save_path\n",
    "        self.type = type\n",
    "        # self.h_el = args.h_el\n",
    "        self.args = args\n",
    "        if not params_search:\n",
    "            self.checkpoints_path = 'tmp/'\n",
    "            if not os.path.exists(self.checkpoints_path):\n",
    "                os.makedirs(self.checkpoints_path)\n",
    "            print(\"***Calling Nearest Neighbour***\")\n",
    "            self.nn = NearestNeighbor(self.target_data_loader, dataset, self.cuda, args.ngf)\n",
    "        self.params_search = params_search\n",
    "        \n",
    "    def train(self, cls=False):\n",
    "        print(\"*** Inside train() func ***\")\n",
    "        if self.type == 'gan':\n",
    "            self._train_gan(cls)\n",
    "        \n",
    "    def _train_gan(self, cls):\n",
    "        print(\"*** Inside _train_gan() func ***\")\n",
    "        criterion = nn.BCELoss()\n",
    "        l2_loss = nn.MSELoss()\n",
    "        l1_loss = nn.L1Loss()\n",
    "        iteration = 0\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for sample in self.data_loader:\n",
    "                iteration += 1\n",
    "                right_images = sample['right_images']\n",
    "                right_embed = sample['right_embed']\n",
    "                wrong_images = sample['wrong_images']\n",
    "\n",
    "                right_images = Variable(right_images.float()).cuda()\n",
    "                right_embed = Variable(right_embed.float()).cuda()\n",
    "                wrong_images = Variable(wrong_images.float()).cuda()\n",
    "\n",
    "                real_labels = torch.ones(right_images.size(0))\n",
    "                fake_labels = torch.zeros(right_images.size(0))\n",
    "\n",
    "                # ======== One sided label smoothing ==========\n",
    "                # Helps preventing the discriminator from overpowering the\n",
    "                # generator adding penalty when the discriminator is too confident\n",
    "                # =============================================\n",
    "                smoothed_real_labels = torch.FloatTensor(Utils.smooth_label(real_labels.numpy(), -0.1))\n",
    "\n",
    "                real_labels = Variable(real_labels).cuda()\n",
    "                smoothed_real_labels = Variable(smoothed_real_labels).cuda()\n",
    "                fake_labels = Variable(fake_labels).cuda()\n",
    "\n",
    "                # Train the discriminator\n",
    "                self.discriminator.zero_grad()\n",
    "                outputs, activation_real = self.discriminator(right_images, right_embed)\n",
    "                real_loss = criterion(outputs, smoothed_real_labels)\n",
    "                real_score = outputs\n",
    "\n",
    "                if cls:\n",
    "                    outputs, _ = self.discriminator(wrong_images, right_embed)\n",
    "                    wrong_loss = criterion(outputs, fake_labels)\n",
    "                    wrong_score = outputs\n",
    "\n",
    "                if self.args.remove_noise:\n",
    "                    noise = Variable(torch.zeros(right_images.size(0), self.noise_dim)).cuda()\n",
    "                else:\n",
    "                    noise = Variable(torch.randn(right_images.size(0), self.noise_dim)).cuda()\n",
    "                noise = noise.view(noise.size(0), 100, 1, 1)\n",
    "                fake_images = self.generator(right_embed, noise, noise)\n",
    "                outputs, _ = self.discriminator(fake_images, right_embed)\n",
    "                fake_loss = criterion(outputs, fake_labels)\n",
    "                fake_score = outputs\n",
    "\n",
    "                d_loss = real_loss + fake_loss\n",
    "\n",
    "                if cls:\n",
    "                    d_loss = d_loss + wrong_loss\n",
    "\n",
    "                d_loss.backward()\n",
    "                self.optimD.step()\n",
    "\n",
    "                # Train the generator\n",
    "                self.generator.zero_grad()\n",
    "                if self.args.remove_noise:\n",
    "                    noise = Variable(torch.zeros(right_images.size(0), self.noise_dim)).cuda()\n",
    "                else:\n",
    "                    noise = Variable(torch.randn(right_images.size(0), self.noise_dim)).cuda()\n",
    "                noise = noise.view(noise.size(0), 100, 1, 1)\n",
    "                fake_images = self.generator(right_embed, noise, noise)\n",
    "                outputs, activation_fake = self.discriminator(fake_images, right_embed)\n",
    "                _, activation_real = self.discriminator(right_images, right_embed)\n",
    "\n",
    "                activation_fake = torch.mean(activation_fake, 0)\n",
    "                activation_real = torch.mean(activation_real, 0)\n",
    "\n",
    "                # ======= Generator Loss function============\n",
    "                # This is a customized loss function, the first term is the regular cross entropy loss\n",
    "                # The second term is feature matching loss, this measure the distance between the real and generated\n",
    "                # images statistics by comparing intermediate layers activations\n",
    "                # The third term is L1 distance between the generated and real images, this is helpful for the conditional case\n",
    "                # because it links the embedding feature vector directly to certain pixel values.\n",
    "                # ===========================================\n",
    "                g_loss = criterion(outputs, real_labels) +\\\n",
    "                         self.l2_coef * l2_loss(activation_fake, activation_real.detach()) +\\\n",
    "                         self.l1_coef * l1_loss(fake_images, right_images)\n",
    "\n",
    "                g_loss.backward()\n",
    "                self.optimG.step()\n",
    "\n",
    "                if iteration % 10 == 0:\n",
    "                    print(\"Epoch: %d, d_loss= %f, g_loss= %f, ccaD(X)= %f, D(G(X))= %f\" % (epoch, d_loss.data.cpu().mean(), g_loss.data.cpu().mean(), real_score.data.cpu().mean(), fake_score.data.cpu().mean()))\n",
    "\n",
    "            if (epoch) % 10 == 0:\n",
    "                Utils.save_checkpoint(self.discriminator, self.generator, self.save_path, epoch)\n",
    "                \n",
    "    def test(self):\n",
    "        self.generator.eval()\n",
    "        self.target_generator.eval()\n",
    "        number_of_images = 2\n",
    "        sample = next(iter(self.data_loader))\n",
    "        all_nn_texts = []\n",
    "        all_nn_images = []\n",
    "        all_fake_sources = []\n",
    "        all_transfers = []\n",
    "        text = sample['txt']\n",
    "        right_images = sample['right_images']\n",
    "        right_embed = sample['right_embed']\n",
    "        for i in range(number_of_images):\n",
    "            right_images_v = Variable(right_images.float(), volatile=True)\n",
    "            right_embed_v = Variable(right_embed.float(), volatile=True)\n",
    "            if self.args.remove_noise:\n",
    "                noise = Variable(torch.zeros(right_images_v.size(0), self.noise_dim), volatile=True)\n",
    "            else:\n",
    "                noise = Variable(torch.randn(right_images_v.size(0), self.noise_dim), volatile=True)\n",
    "            if self.cuda:\n",
    "                right_embed_v = right_embed_v.cuda()\n",
    "                noise = noise.cuda()\n",
    "\n",
    "            noise = noise.view(noise.size(0), self.noise_dim, 1, 1)\n",
    "            #print(\"right_embed_v type = \",type(right_embed_v),\"noise = \",type(noise))\n",
    "            fake_target = self.target_generator.generator_only(self.generator.encoder_only(right_embed_v, noise, noise))\n",
    "            all_transfers.append(fake_target)\n",
    "            fake_source = self.generator(right_embed_v, noise,noise)\n",
    "            all_fake_sources.append(fake_source)\n",
    "            \n",
    "            fake_source = fake_source.cuda()\n",
    "            print(\"fake_source shape: \",fake_source.detach().shape)\n",
    "            print(\"text description: \",text[0])\n",
    "            plt.imshow(fake_source[0].cpu().detach().permute(1, 2, 0))\n",
    "            plt.show()\n",
    "\n",
    "            nn_text, nn_images = self.nn.get_text_and_images(fake_target, -1)\n",
    "            all_nn_texts.append(nn_text)\n",
    "            all_nn_images.append(nn_images)\n",
    "            \n",
    "        for i, sentence in enumerate(text):\n",
    "            nn_sentences = [sents[i] for sents in all_nn_texts]\n",
    "            print(\"\\ncombined text: \",i,\"original sentence: \",sentence,\"nn_sentences: \",nn_sentences)\n",
    "\n",
    "        for i, image in enumerate(right_images):\n",
    "            nn_images = [imgs[i] for imgs in all_nn_images]\n",
    "            fake_source_images = [imgs[i].data.cpu().numpy() for imgs in all_fake_sources]\n",
    "            transfers_images = [imgs[i].data.cpu().numpy() for imgs in all_transfers]\n",
    "            image_tile = np.tile(image, (len(nn_images), 1, 1, 1))\n",
    "            #self.logger.draw_test(image_tile, fake_source_images, transfers_images, nn_images, 'image {}'.format(i))\n",
    "        print(\"*** end of testing ***\")\n",
    "   \n",
    "################ trainer.py ends here ###################\n",
    "\n",
    "################ runtime.py ###################\n",
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "        \n",
    "parser = argparse.ArgumentParser()\n",
    "params = dict()\n",
    "\n",
    "params['type']='gan' #change this if you want to train any other gan\n",
    "params['target_type']='vae'\n",
    "params['lr']=0.0002\n",
    "params['l1_coef']=50\n",
    "params['l2_coef']=100\n",
    "params['diter']=5\n",
    "params['cls']=False\n",
    "params['save_path']='tmp/'\n",
    "params['inference']=False\n",
    "params['target_train']=False\n",
    "params['dataset']='flowers_only'\n",
    "params['split']=0\n",
    "params['batch_size']=128\n",
    "params['num_workers']=1\n",
    "params['ngf']=64\n",
    "params['epochs']=1\n",
    "params['remove_noise']=False\n",
    "params['remove_noise_2']=False\n",
    "params['variational']=False\n",
    "params['vis_screen']=False\n",
    "params['pre_trained_disc']=False\n",
    "params['pre_trained_gen']=False\n",
    "params['flowers_dataset_path']=\"../input/flowershd5dataset/flowers-hd5/data/flowers/flowers.hdf5\"\n",
    "\n",
    "args = Struct(**params) #Convert nested Python dict to object\n",
    "\n",
    "trainer = Trainer(type=args.type, dataset=args.dataset, split=args.split, lr=args.lr, diter=args.diter,\n",
    "                  vis_screen=args.vis_screen, save_path=args.save_path, l1_coef=args.l1_coef, \n",
    "                  l2_coef=args.l2_coef,pre_trained_disc=args.pre_trained_disc, \n",
    "                  pre_trained_gen=args.pre_trained_gen, batch_size=args.batch_size, \n",
    "                  num_workers=args.num_workers, epochs=args.epochs, args=args)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "if not args.inference:\n",
    "    if args.target_train:\n",
    "        trainer.target_train(args.cls)\n",
    "    else:\n",
    "        trainer.train(args.cls)\n",
    "print(\"*** Calling test() ***\")\n",
    "trainer.test()\n",
    "\n",
    "elapsed = str(timedelta(seconds=int(time.time() - start_time)))\n",
    "print('Running {} took {}'.format(\"GAN-CLS\", elapsed))\n",
    "\n",
    "################ runtime.py ends here ###################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
